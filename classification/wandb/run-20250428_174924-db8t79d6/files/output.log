Not using distributed mode
Namespace(mode='train', batch_size=128, epochs=50, update_freq=1, save_ckpt_freq=5, model='PanDerm_Large_FT', rel_pos_bias=True, sin_pos_emb=True, layer_scale_init_value=0.1, ood_eval=False, input_size=224, drop=0.0, attn_drop_rate=0.0, drop_path=0.2, weights=True, disable_eval_during_finetuning=False, model_ema=False, model_ema_decay=0.9999, model_ema_force_cpu=False, percent_data=1.0, TTA=False, monitor='acc', opt='adamw', opt_eps=1e-08, opt_betas=None, clip_grad=None, momentum=0.9, weight_decay=0.05, weight_decay_end=None, lr=0.0005, layer_decay=0.65, warmup_lr=1e-06, min_lr=1e-06, warmup_epochs=10, warmup_steps=-1, color_jitter=0.4, aa='rand-m9-mstd0.5-inc1', smoothing=0.1, train_interpolation='bicubic', crop_pct=None, reprob=0.25, remode='pixel', recount=1, resplit=False, mixup=0.8, cutmix=1.0, cutmix_minmax=None, mixup_prob=1.0, mixup_switch_prob=0.5, mixup_mode='batch', pretrained_checkpoint='/home/syyan/XJ/PanDerm-open_source/pretrain_weight/panderm_ll_data6_checkpoint-499.pth', model_key='model|module|state_dict', model_prefix='', init_scale=0.001, use_mean_pooling=True, disable_weight_decay_on_rel_pos_bias=False, data_path='/datasets01/imagenet_full_size/061417/', eval_data_path=None, test_csv_path=None, image_key='image', nb_classes=7, imagenet_default_mean_and_std=True, data_set='IMNET', csv_path='/home/share/Uni_Eval/pad-ufes/2000.csv', root_path='/home/share/Uni_Eval/pad-ufes/images/', output_dir='/home/share/FM_Code/PanDerm/Output_dir/', log_dir=None, device='cuda', seed=122, resume='', auto_resume=False, wandb_name='Reproduce_PAD_FT128_5e-4_122', save_ckpt=True, start_epoch=0, eval=False, dist_eval=False, num_workers=10, pin_mem=True, world_size=1, local_rank=-1, dist_on_itp=False, dist_url='env://', enable_deepspeed=False, enable_linear_eval=False, enable_multi_print=False, exp_name='ham finetune and eval', distributed=False)
Label distribution:
Label 0: 174
Label 1: 543
Label 2: 464
Label 3: 154
Label 4: 123
Label 5: 35
Using WeightedRandomSampler
train size: 1493 ,val size: 344 ,test size: 461
Mixup is activated!
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at ../aten/src/ATen/native/TensorShape.cpp:3609.)
  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (1): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.008695652708411217)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.017391305416822433)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (3): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.02608695812523365)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (4): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.03478261083364487)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (5): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.04347826540470123)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (6): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.0521739162504673)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (7): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.06086956709623337)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (8): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.06956522166728973)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (9): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.0782608762383461)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (10): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.08695653080940247)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (11): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.09565217792987823)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (12): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.104347825050354)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (13): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.11304347217082977)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (14): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.12173912674188614)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (15): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.1304347813129425)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (16): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.13913042843341827)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (17): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.14782609045505524)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (18): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.156521737575531)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (19): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.16521739959716797)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (20): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.17391304671764374)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (21): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.1826086938381195)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (22): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.19130435585975647)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (23): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.20000000298023224)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): Identity()
  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=7, bias=True)
)
Patch size = (16, 16)
/home/share/FM_Code/PanDerm/classification/run_class_finetuning.py:432: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  checkpoint = torch.load(args.pretrained_checkpoint, map_location='cpu')
Load ckpt from /home/syyan/XJ/PanDerm-open_source/pretrain_weight/panderm_ll_data6_checkpoint-499.pth
Load state_dict by model_key = model
all keys: ['encoder.cls_token', 'encoder.pos_embed', 'encoder.patch_embed.proj.weight', 'encoder.patch_embed.proj.bias', 'encoder.blocks.0.gamma_1', 'encoder.blocks.0.gamma_2', 'encoder.blocks.0.norm1.weight', 'encoder.blocks.0.norm1.bias', 'encoder.blocks.0.attn.q_bias', 'encoder.blocks.0.attn.v_bias', 'encoder.blocks.0.attn.qkv.weight', 'encoder.blocks.0.attn.proj.weight', 'encoder.blocks.0.attn.proj.bias', 'encoder.blocks.0.norm2.weight', 'encoder.blocks.0.norm2.bias', 'encoder.blocks.0.mlp.fc1.weight', 'encoder.blocks.0.mlp.fc1.bias', 'encoder.blocks.0.mlp.fc2.weight', 'encoder.blocks.0.mlp.fc2.bias', 'encoder.blocks.1.gamma_1', 'encoder.blocks.1.gamma_2', 'encoder.blocks.1.norm1.weight', 'encoder.blocks.1.norm1.bias', 'encoder.blocks.1.attn.q_bias', 'encoder.blocks.1.attn.v_bias', 'encoder.blocks.1.attn.qkv.weight', 'encoder.blocks.1.attn.proj.weight', 'encoder.blocks.1.attn.proj.bias', 'encoder.blocks.1.norm2.weight', 'encoder.blocks.1.norm2.bias', 'encoder.blocks.1.mlp.fc1.weight', 'encoder.blocks.1.mlp.fc1.bias', 'encoder.blocks.1.mlp.fc2.weight', 'encoder.blocks.1.mlp.fc2.bias', 'encoder.blocks.2.gamma_1', 'encoder.blocks.2.gamma_2', 'encoder.blocks.2.norm1.weight', 'encoder.blocks.2.norm1.bias', 'encoder.blocks.2.attn.q_bias', 'encoder.blocks.2.attn.v_bias', 'encoder.blocks.2.attn.qkv.weight', 'encoder.blocks.2.attn.proj.weight', 'encoder.blocks.2.attn.proj.bias', 'encoder.blocks.2.norm2.weight', 'encoder.blocks.2.norm2.bias', 'encoder.blocks.2.mlp.fc1.weight', 'encoder.blocks.2.mlp.fc1.bias', 'encoder.blocks.2.mlp.fc2.weight', 'encoder.blocks.2.mlp.fc2.bias', 'encoder.blocks.3.gamma_1', 'encoder.blocks.3.gamma_2', 'encoder.blocks.3.norm1.weight', 'encoder.blocks.3.norm1.bias', 'encoder.blocks.3.attn.q_bias', 'encoder.blocks.3.attn.v_bias', 'encoder.blocks.3.attn.qkv.weight', 'encoder.blocks.3.attn.proj.weight', 'encoder.blocks.3.attn.proj.bias', 'encoder.blocks.3.norm2.weight', 'encoder.blocks.3.norm2.bias', 'encoder.blocks.3.mlp.fc1.weight', 'encoder.blocks.3.mlp.fc1.bias', 'encoder.blocks.3.mlp.fc2.weight', 'encoder.blocks.3.mlp.fc2.bias', 'encoder.blocks.4.gamma_1', 'encoder.blocks.4.gamma_2', 'encoder.blocks.4.norm1.weight', 'encoder.blocks.4.norm1.bias', 'encoder.blocks.4.attn.q_bias', 'encoder.blocks.4.attn.v_bias', 'encoder.blocks.4.attn.qkv.weight', 'encoder.blocks.4.attn.proj.weight', 'encoder.blocks.4.attn.proj.bias', 'encoder.blocks.4.norm2.weight', 'encoder.blocks.4.norm2.bias', 'encoder.blocks.4.mlp.fc1.weight', 'encoder.blocks.4.mlp.fc1.bias', 'encoder.blocks.4.mlp.fc2.weight', 'encoder.blocks.4.mlp.fc2.bias', 'encoder.blocks.5.gamma_1', 'encoder.blocks.5.gamma_2', 'encoder.blocks.5.norm1.weight', 'encoder.blocks.5.norm1.bias', 'encoder.blocks.5.attn.q_bias', 'encoder.blocks.5.attn.v_bias', 'encoder.blocks.5.attn.qkv.weight', 'encoder.blocks.5.attn.proj.weight', 'encoder.blocks.5.attn.proj.bias', 'encoder.blocks.5.norm2.weight', 'encoder.blocks.5.norm2.bias', 'encoder.blocks.5.mlp.fc1.weight', 'encoder.blocks.5.mlp.fc1.bias', 'encoder.blocks.5.mlp.fc2.weight', 'encoder.blocks.5.mlp.fc2.bias', 'encoder.blocks.6.gamma_1', 'encoder.blocks.6.gamma_2', 'encoder.blocks.6.norm1.weight', 'encoder.blocks.6.norm1.bias', 'encoder.blocks.6.attn.q_bias', 'encoder.blocks.6.attn.v_bias', 'encoder.blocks.6.attn.qkv.weight', 'encoder.blocks.6.attn.proj.weight', 'encoder.blocks.6.attn.proj.bias', 'encoder.blocks.6.norm2.weight', 'encoder.blocks.6.norm2.bias', 'encoder.blocks.6.mlp.fc1.weight', 'encoder.blocks.6.mlp.fc1.bias', 'encoder.blocks.6.mlp.fc2.weight', 'encoder.blocks.6.mlp.fc2.bias', 'encoder.blocks.7.gamma_1', 'encoder.blocks.7.gamma_2', 'encoder.blocks.7.norm1.weight', 'encoder.blocks.7.norm1.bias', 'encoder.blocks.7.attn.q_bias', 'encoder.blocks.7.attn.v_bias', 'encoder.blocks.7.attn.qkv.weight', 'encoder.blocks.7.attn.proj.weight', 'encoder.blocks.7.attn.proj.bias', 'encoder.blocks.7.norm2.weight', 'encoder.blocks.7.norm2.bias', 'encoder.blocks.7.mlp.fc1.weight', 'encoder.blocks.7.mlp.fc1.bias', 'encoder.blocks.7.mlp.fc2.weight', 'encoder.blocks.7.mlp.fc2.bias', 'encoder.blocks.8.gamma_1', 'encoder.bl
##############new keys: 454 odict_keys(['rd_pos_embed', 'mask_token', 'regresser.regressor_blocks.0.gamma_1_cross', 'regresser.regressor_blocks.0.gamma_2_cross', 'regresser.regressor_blocks.0.norm1_q.weight', 'regresser.regressor_blocks.0.norm1_q.bias', 'regresser.regressor_blocks.0.norm1_k.weight', 'regresser.regressor_blocks.0.norm1_k.bias', 'regresser.regressor_blocks.0.norm1_v.weight', 'regresser.regressor_blocks.0.norm1_v.bias', 'regresser.regressor_blocks.0.norm2_cross.weight', 'regresser.regressor_blocks.0.norm2_cross.bias', 'regresser.regressor_blocks.0.cross_attn.q_bias', 'regresser.regressor_blocks.0.cross_attn.v_bias', 'regresser.regressor_blocks.0.cross_attn.q.weight', 'regresser.regressor_blocks.0.cross_attn.k.weight', 'regresser.regressor_blocks.0.cross_attn.v.weight', 'regresser.regressor_blocks.0.cross_attn.proj.weight', 'regresser.regressor_blocks.0.cross_attn.proj.bias', 'regresser.regressor_blocks.0.mlp_cross.fc1.weight', 'regresser.regressor_blocks.0.mlp_cross.fc1.bias', 'regresser.regressor_blocks.0.mlp_cross.fc2.weight', 'regresser.regressor_blocks.0.mlp_cross.fc2.bias', 'regresser.regressor_blocks.1.gamma_1_cross', 'regresser.regressor_blocks.1.gamma_2_cross', 'regresser.regressor_blocks.1.norm1_q.weight', 'regresser.regressor_blocks.1.norm1_q.bias', 'regresser.regressor_blocks.1.norm1_k.weight', 'regresser.regressor_blocks.1.norm1_k.bias', 'regresser.regressor_blocks.1.norm1_v.weight', 'regresser.regressor_blocks.1.norm1_v.bias', 'regresser.regressor_blocks.1.norm2_cross.weight', 'regresser.regressor_blocks.1.norm2_cross.bias', 'regresser.regressor_blocks.1.cross_attn.q_bias', 'regresser.regressor_blocks.1.cross_attn.v_bias', 'regresser.regressor_blocks.1.cross_attn.q.weight', 'regresser.regressor_blocks.1.cross_attn.k.weight', 'regresser.regressor_blocks.1.cross_attn.v.weight', 'regresser.regressor_blocks.1.cross_attn.proj.weight', 'regresser.regressor_blocks.1.cross_attn.proj.bias', 'regresser.regressor_blocks.1.mlp_cross.fc1.weight', 'regresser.regressor_blocks.1.mlp_cross.fc1.bias', 'regresser.regressor_blocks.1.mlp_cross.fc2.weight', 'regresser.regressor_blocks.1.mlp_cross.fc2.bias', 'regresser.regressor_blocks.2.gamma_1_cross', 'regresser.regressor_blocks.2.gamma_2_cross', 'regresser.regressor_blocks.2.norm1_q.weight', 'regresser.regressor_blocks.2.norm1_q.bias', 'regresser.regressor_blocks.2.norm1_k.weight', 'regresser.regressor_blocks.2.norm1_k.bias', 'regresser.regressor_blocks.2.norm1_v.weight', 'regresser.regressor_blocks.2.norm1_v.bias', 'regresser.regressor_blocks.2.norm2_cross.weight', 'regresser.regressor_blocks.2.norm2_cross.bias', 'regresser.regressor_blocks.2.cross_attn.q_bias', 'regresser.regressor_blocks.2.cross_attn.v_bias', 'regresser.regressor_blocks.2.cross_attn.q.weight', 'regresser.regressor_blocks.2.cross_attn.k.weight', 'regresser.regressor_blocks.2.cross_attn.v.weight', 'regresser.regressor_blocks.2.cross_attn.proj.weight', 'regresser.regressor_blocks.2.cross_attn.proj.bias', 'regresser.regressor_blocks.2.mlp_cross.fc1.weight', 'regresser.regressor_blocks.2.mlp_cross.fc1.bias', 'regresser.regressor_blocks.2.mlp_cross.fc2.weight', 'regresser.regressor_blocks.2.mlp_cross.fc2.bias', 'regresser.regressor_blocks.3.gamma_1_cross', 'regresser.regressor_blocks.3.gamma_2_cross', 'regresser.regressor_blocks.3.norm1_q.weight', 'regresser.regressor_blocks.3.norm1_q.bias', 'regresser.regressor_blocks.3.norm1_k.weight', 'regresser.regressor_blocks.3.norm1_k.bias', 'regresser.regressor_blocks.3.norm1_v.weight', 'regresser.regressor_blocks.3.norm1_v.bias', 'regresser.regressor_blocks.3.norm2_cross.weight', 'regresser.regressor_blocks.3.norm2_cross.bias', 'regresser.regressor_blocks.3.cross_attn.q_bias', 'regresser.regressor_blocks.3.cross_attn.v_bias', 'regresser.regressor_blocks.3.cross_attn.q.weight', 'regresser.regressor_blocks.3.cross_attn.k.weight', 'regresser.regressor_blocks.3.cross_attn.v.weight', 'regresser.regressor_blocks.3.cross_attn.proj.weight', 'regresser.regressor_blocks.3.cross_attn.proj.bias', 'regresser.regressor_blocks.3.mlp_cross.fc1.weight', 'regresser.regressor_
Weights of VisionTransformer not initialized from pretrained model: ['blocks.0.attn.relative_position_bias_table', 'blocks.1.attn.relative_position_bias_table', 'blocks.2.attn.relative_position_bias_table', 'blocks.3.attn.relative_position_bias_table', 'blocks.4.attn.relative_position_bias_table', 'blocks.5.attn.relative_position_bias_table', 'blocks.6.attn.relative_position_bias_table', 'blocks.7.attn.relative_position_bias_table', 'blocks.8.attn.relative_position_bias_table', 'blocks.9.attn.relative_position_bias_table', 'blocks.10.attn.relative_position_bias_table', 'blocks.11.attn.relative_position_bias_table', 'blocks.12.attn.relative_position_bias_table', 'blocks.13.attn.relative_position_bias_table', 'blocks.14.attn.relative_position_bias_table', 'blocks.15.attn.relative_position_bias_table', 'blocks.16.attn.relative_position_bias_table', 'blocks.17.attn.relative_position_bias_table', 'blocks.18.attn.relative_position_bias_table', 'blocks.19.attn.relative_position_bias_table', 'blocks.20.attn.relative_position_bias_table', 'blocks.21.attn.relative_position_bias_table', 'blocks.22.attn.relative_position_bias_table', 'blocks.23.attn.relative_position_bias_table', 'head.weight', 'head.bias']
Weights from pretrained model not used in VisionTransformer: ['rd_pos_embed', 'mask_token', 'regresser.regressor_blocks.0.gamma_1_cross', 'regresser.regressor_blocks.0.gamma_2_cross', 'regresser.regressor_blocks.0.norm1_q.weight', 'regresser.regressor_blocks.0.norm1_q.bias', 'regresser.regressor_blocks.0.norm1_k.weight', 'regresser.regressor_blocks.0.norm1_k.bias', 'regresser.regressor_blocks.0.norm1_v.weight', 'regresser.regressor_blocks.0.norm1_v.bias', 'regresser.regressor_blocks.0.norm2_cross.weight', 'regresser.regressor_blocks.0.norm2_cross.bias', 'regresser.regressor_blocks.0.cross_attn.q_bias', 'regresser.regressor_blocks.0.cross_attn.v_bias', 'regresser.regressor_blocks.0.cross_attn.q.weight', 'regresser.regressor_blocks.0.cross_attn.k.weight', 'regresser.regressor_blocks.0.cross_attn.v.weight', 'regresser.regressor_blocks.0.cross_attn.proj.weight', 'regresser.regressor_blocks.0.cross_attn.proj.bias', 'regresser.regressor_blocks.0.mlp_cross.fc1.weight', 'regresser.regressor_blocks.0.mlp_cross.fc1.bias', 'regresser.regressor_blocks.0.mlp_cross.fc2.weight', 'regresser.regressor_blocks.0.mlp_cross.fc2.bias', 'regresser.regressor_blocks.1.gamma_1_cross', 'regresser.regressor_blocks.1.gamma_2_cross', 'regresser.regressor_blocks.1.norm1_q.weight', 'regresser.regressor_blocks.1.norm1_q.bias', 'regresser.regressor_blocks.1.norm1_k.weight', 'regresser.regressor_blocks.1.norm1_k.bias', 'regresser.regressor_blocks.1.norm1_v.weight', 'regresser.regressor_blocks.1.norm1_v.bias', 'regresser.regressor_blocks.1.norm2_cross.weight', 'regresser.regressor_blocks.1.norm2_cross.bias', 'regresser.regressor_blocks.1.cross_attn.q_bias', 'regresser.regressor_blocks.1.cross_attn.v_bias', 'regresser.regressor_blocks.1.cross_attn.q.weight', 'regresser.regressor_blocks.1.cross_attn.k.weight', 'regresser.regressor_blocks.1.cross_attn.v.weight', 'regresser.regressor_blocks.1.cross_attn.proj.weight', 'regresser.regressor_blocks.1.cross_attn.proj.bias', 'regresser.regressor_blocks.1.mlp_cross.fc1.weight', 'regresser.regressor_blocks.1.mlp_cross.fc1.bias', 'regresser.regressor_blocks.1.mlp_cross.fc2.weight', 'regresser.regressor_blocks.1.mlp_cross.fc2.bias', 'regresser.regressor_blocks.2.gamma_1_cross', 'regresser.regressor_blocks.2.gamma_2_cross', 'regresser.regressor_blocks.2.norm1_q.weight', 'regresser.regressor_blocks.2.norm1_q.bias', 'regresser.regressor_blocks.2.norm1_k.weight', 'regresser.regressor_blocks.2.norm1_k.bias', 'regresser.regressor_blocks.2.norm1_v.weight', 'regresser.regressor_blocks.2.norm1_v.bias', 'regresser.regressor_blocks.2.norm2_cross.weight', 'regresser.regressor_blocks.2.norm2_cross.bias', 'regresser.regressor_blocks.2.cross_attn.q_bias', 'regresser.regressor_blocks.2.cross_attn.v_bias', 'regresser.regressor_blocks.2.cross_attn.q.weight', 'regresser.regressor_blocks.2.cross_attn.k.weight', 'regresser.regressor_blocks.2.cross_attn.v.weight', 'regresser.regressor_blocks.2.cross_attn.proj.weight', 'regresser.regressor_blocks.2.cross_attn.proj.bias', 'regresser.regressor_blocks.2.mlp_cross.fc1.weight', 'regresser.regressor_blocks.2.mlp_cross.fc1.bias', 'regresser.regressor_blocks.2.mlp_cross.fc2.weight', 'regresser.regressor_blocks.2.mlp_cross.fc2.bias', 'regresser.regressor_blocks.3.gamma_1_cross', 'regresser.regressor_blocks.3.gamma_2_cross', 'regresser.regressor_blocks.3.norm1_q.weight', 'regresser.regressor_blocks.3.norm1_q.bias', 'regresser.regressor_blocks.3.norm1_k.weight', 'regresser.regressor_blocks.3.norm1_k.bias', 'regresser.regressor_blocks.3.norm1_v.weight', 'regresser.regressor_blocks.3.norm1_v.bias', 'regresser.regressor_blocks.3.norm2_cross.weight', 'regresser.regressor_blocks.3.norm2_cross.bias', 'regresser.regressor_blocks.3.cross_attn.q_bias', 'regresser.regressor_blocks.3.cross_attn.v_bias', 'regresser.regressor_blocks.3.cross_attn.q.weight', 'regresser.regressor_blocks.3.cross_attn.k.weight', 'regresser.regressor_blocks.3.cross_attn.v.weight', 'regresser.regressor_blocks.3.cross_attn.proj.weight', 'regresser.regressor_blocks.3.cross_attn.proj.bias', 'regresser.regressor_blocks.3.mlp_cross.fc1.weight',
Ignored weights of VisionTransformer not initialized from pretrained model: ['blocks.0.attn.relative_position_index', 'blocks.1.attn.relative_position_index', 'blocks.2.attn.relative_position_index', 'blocks.3.attn.relative_position_index', 'blocks.4.attn.relative_position_index', 'blocks.5.attn.relative_position_index', 'blocks.6.attn.relative_position_index', 'blocks.7.attn.relative_position_index', 'blocks.8.attn.relative_position_index', 'blocks.9.attn.relative_position_index', 'blocks.10.attn.relative_position_index', 'blocks.11.attn.relative_position_index', 'blocks.12.attn.relative_position_index', 'blocks.13.attn.relative_position_index', 'blocks.14.attn.relative_position_index', 'blocks.15.attn.relative_position_index', 'blocks.16.attn.relative_position_index', 'blocks.17.attn.relative_position_index', 'blocks.18.attn.relative_position_index', 'blocks.19.attn.relative_position_index', 'blocks.20.attn.relative_position_index', 'blocks.21.attn.relative_position_index', 'blocks.22.attn.relative_position_index', 'blocks.23.attn.relative_position_index']
Model = VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 1024, kernel_size=(16, 16), stride=(16, 16))
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (blocks): ModuleList(
    (0): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (1): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.008695652708411217)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (2): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.017391305416822433)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (3): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.02608695812523365)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (4): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.03478261083364487)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (5): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.04347826540470123)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (6): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.0521739162504673)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (7): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.06086956709623337)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (8): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.06956522166728973)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (9): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.0782608762383461)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (10): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.08695653080940247)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (11): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.09565217792987823)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (12): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.104347825050354)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (13): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.11304347217082977)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (14): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.12173912674188614)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (15): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.1304347813129425)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (16): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.13913042843341827)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (17): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.14782609045505524)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (18): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.156521737575531)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (19): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.16521739959716797)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (20): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.17391304671764374)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (21): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.1826086938381195)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (22): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.19130435585975647)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
    (23): Block(
      (norm1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=1024, out_features=3072, bias=False)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=1024, out_features=1024, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): DropPath(p=0.20000000298023224)
      (norm2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
      (mlp): Mlp(
        (fc1): Linear(in_features=1024, out_features=4096, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=4096, out_features=1024, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): Identity()
  (fc_norm): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
  (head): Linear(in_features=1024, out_features=7, bias=True)
)
number of params: 303412743
LR = 0.00050000
Batch size = 128
Update frequent = 1
Number of training examples = 1493
Number of training training per epoch = 11
Assigned values = [2.1029740616282293e-05, 3.2353447101972754e-05, 4.977453400303501e-05, 7.65762061585154e-05, 0.00011780954793617752, 0.00018124545836335003, 0.0002788391667128462, 0.0004289833334043787, 0.0006599743590836596, 0.0010153451678210146, 0.0015620694889554071, 0.002403183829162165, 0.003697205891018715, 0.005688009063105715, 0.008750783174008792, 0.013462743344628911, 0.02071191283789063, 0.03186448128906251, 0.049022278906250015, 0.07541889062500001, 0.11602906250000002, 0.17850625000000003, 0.274625, 0.42250000000000004, 0.65, 1.0]
Skip weight decay list:  {'pos_embed', 'cls_token'}
Param groups = {
  "layer_0_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "cls_token",
      "patch_embed.proj.bias"
    ],
    "lr_scale": 2.1029740616282293e-05
  },
  "layer_0_decay": {
    "weight_decay": 0.05,
    "params": [
      "patch_embed.proj.weight"
    ],
    "lr_scale": 2.1029740616282293e-05
  },
  "layer_1_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.0.gamma_1",
      "blocks.0.gamma_2",
      "blocks.0.norm1.weight",
      "blocks.0.norm1.bias",
      "blocks.0.attn.q_bias",
      "blocks.0.attn.v_bias",
      "blocks.0.attn.proj.bias",
      "blocks.0.norm2.weight",
      "blocks.0.norm2.bias",
      "blocks.0.mlp.fc1.bias",
      "blocks.0.mlp.fc2.bias"
    ],
    "lr_scale": 3.2353447101972754e-05
  },
  "layer_1_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.0.attn.relative_position_bias_table",
      "blocks.0.attn.qkv.weight",
      "blocks.0.attn.proj.weight",
      "blocks.0.mlp.fc1.weight",
      "blocks.0.mlp.fc2.weight"
    ],
    "lr_scale": 3.2353447101972754e-05
  },
  "layer_2_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.1.gamma_1",
      "blocks.1.gamma_2",
      "blocks.1.norm1.weight",
      "blocks.1.norm1.bias",
      "blocks.1.attn.q_bias",
      "blocks.1.attn.v_bias",
      "blocks.1.attn.proj.bias",
      "blocks.1.norm2.weight",
      "blocks.1.norm2.bias",
      "blocks.1.mlp.fc1.bias",
      "blocks.1.mlp.fc2.bias"
    ],
    "lr_scale": 4.977453400303501e-05
  },
  "layer_2_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.1.attn.relative_position_bias_table",
      "blocks.1.attn.qkv.weight",
      "blocks.1.attn.proj.weight",
      "blocks.1.mlp.fc1.weight",
      "blocks.1.mlp.fc2.weight"
    ],
    "lr_scale": 4.977453400303501e-05
  },
  "layer_3_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.2.gamma_1",
      "blocks.2.gamma_2",
      "blocks.2.norm1.weight",
      "blocks.2.norm1.bias",
      "blocks.2.attn.q_bias",
      "blocks.2.attn.v_bias",
      "blocks.2.attn.proj.bias",
      "blocks.2.norm2.weight",
      "blocks.2.norm2.bias",
      "blocks.2.mlp.fc1.bias",
      "blocks.2.mlp.fc2.bias"
    ],
    "lr_scale": 7.65762061585154e-05
  },
  "layer_3_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.2.attn.relative_position_bias_table",
      "blocks.2.attn.qkv.weight",
      "blocks.2.attn.proj.weight",
      "blocks.2.mlp.fc1.weight",
      "blocks.2.mlp.fc2.weight"
    ],
    "lr_scale": 7.65762061585154e-05
  },
  "layer_4_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.3.gamma_1",
      "blocks.3.gamma_2",
      "blocks.3.norm1.weight",
      "blocks.3.norm1.bias",
      "blocks.3.attn.q_bias",
      "blocks.3.attn.v_bias",
      "blocks.3.attn.proj.bias",
      "blocks.3.norm2.weight",
      "blocks.3.norm2.bias",
      "blocks.3.mlp.fc1.bias",
      "blocks.3.mlp.fc2.bias"
    ],
    "lr_scale": 0.00011780954793617752
  },
  "layer_4_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.3.attn.relative_position_bias_table",
      "blocks.3.attn.qkv.weight",
      "blocks.3.attn.proj.weight",
      "blocks.3.mlp.fc1.weight",
      "blocks.3.mlp.fc2.weight"
    ],
    "lr_scale": 0.00011780954793617752
  },
  "layer_5_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.4.gamma_1",
      "blocks.4.gamma_2",
      "blocks.4.norm1.weight",
      "blocks.4.norm1.bias",
      "blocks.4.attn.q_bias",
      "blocks.4.attn.v_bias",
      "blocks.4.attn.proj.bias",
      "blocks.4.norm2.weight",
      "blocks.4.norm2.bias",
      "blocks.4.mlp.fc1.bias",
      "blocks.4.mlp.fc2.bias"
    ],
    "lr_scale": 0.00018124545836335003
  },
  "layer_5_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.4.attn.relative_position_bias_table",
      "blocks.4.attn.qkv.weight",
      "blocks.4.attn.proj.weight",
      "blocks.4.mlp.fc1.weight",
      "blocks.4.mlp.fc2.weight"
    ],
    "lr_scale": 0.00018124545836335003
  },
  "layer_6_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.5.gamma_1",
      "blocks.5.gamma_2",
      "blocks.5.norm1.weight",
      "blocks.5.norm1.bias",
      "blocks.5.attn.q_bias",
      "blocks.5.attn.v_bias",
      "blocks.5.attn.proj.bias",
      "blocks.5.norm2.weight",
      "blocks.5.norm2.bias",
      "blocks.5.mlp.fc1.bias",
      "blocks.5.mlp.fc2.bias"
    ],
    "lr_scale": 0.0002788391667128462
  },
  "layer_6_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.5.attn.relative_position_bias_table",
      "blocks.5.attn.qkv.weight",
      "blocks.5.attn.proj.weight",
      "blocks.5.mlp.fc1.weight",
      "blocks.5.mlp.fc2.weight"
    ],
    "lr_scale": 0.0002788391667128462
  },
  "layer_7_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.6.gamma_1",
      "blocks.6.gamma_2",
      "blocks.6.norm1.weight",
      "blocks.6.norm1.bias",
      "blocks.6.attn.q_bias",
      "blocks.6.attn.v_bias",
      "blocks.6.attn.proj.bias",
      "blocks.6.norm2.weight",
      "blocks.6.norm2.bias",
      "blocks.6.mlp.fc1.bias",
      "blocks.6.mlp.fc2.bias"
    ],
    "lr_scale": 0.0004289833334043787
  },
  "layer_7_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.6.attn.relative_position_bias_table",
      "blocks.6.attn.qkv.weight",
      "blocks.6.attn.proj.weight",
      "blocks.6.mlp.fc1.weight",
      "blocks.6.mlp.fc2.weight"
    ],
    "lr_scale": 0.0004289833334043787
  },
  "layer_8_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.7.gamma_1",
      "blocks.7.gamma_2",
      "blocks.7.norm1.weight",
      "blocks.7.norm1.bias",
      "blocks.7.attn.q_bias",
      "blocks.7.attn.v_bias",
      "blocks.7.attn.proj.bias",
      "blocks.7.norm2.weight",
      "blocks.7.norm2.bias",
      "blocks.7.mlp.fc1.bias",
      "blocks.7.mlp.fc2.bias"
    ],
    "lr_scale": 0.0006599743590836596
  },
  "layer_8_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.7.attn.relative_position_bias_table",
      "blocks.7.attn.qkv.weight",
      "blocks.7.attn.proj.weight",
      "blocks.7.mlp.fc1.weight",
      "blocks.7.mlp.fc2.weight"
    ],
    "lr_scale": 0.0006599743590836596
  },
  "layer_9_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.8.gamma_1",
      "blocks.8.gamma_2",
      "blocks.8.norm1.weight",
      "blocks.8.norm1.bias",
      "blocks.8.attn.q_bias",
      "blocks.8.attn.v_bias",
      "blocks.8.attn.proj.bias",
      "blocks.8.norm2.weight",
      "blocks.8.norm2.bias",
      "blocks.8.mlp.fc1.bias",
      "blocks.8.mlp.fc2.bias"
    ],
    "lr_scale": 0.0010153451678210146
  },
  "layer_9_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.8.attn.relative_position_bias_table",
      "blocks.8.attn.qkv.weight",
      "blocks.8.attn.proj.weight",
      "blocks.8.mlp.fc1.weight",
      "blocks.8.mlp.fc2.weight"
    ],
    "lr_scale": 0.0010153451678210146
  },
  "layer_10_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.9.gamma_1",
      "blocks.9.gamma_2",
      "blocks.9.norm1.weight",
      "blocks.9.norm1.bias",
      "blocks.9.attn.q_bias",
      "blocks.9.attn.v_bias",
      "blocks.9.attn.proj.bias",
      "blocks.9.norm2.weight",
      "blocks.9.norm2.bias",
      "blocks.9.mlp.fc1.bias",
      "blocks.9.mlp.fc2.bias"
    ],
    "lr_scale": 0.0015620694889554071
  },
  "layer_10_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.9.attn.relative_position_bias_table",
      "blocks.9.attn.qkv.weight",
      "blocks.9.attn.proj.weight",
      "blocks.9.mlp.fc1.weight",
      "blocks.9.mlp.fc2.weight"
    ],
    "lr_scale": 0.0015620694889554071
  },
  "layer_11_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.10.gamma_1",
      "blocks.10.gamma_2",
      "blocks.10.norm1.weight",
      "blocks.10.norm1.bias",
      "blocks.10.attn.q_bias",
      "blocks.10.attn.v_bias",
      "blocks.10.attn.proj.bias",
      "blocks.10.norm2.weight",
      "blocks.10.norm2.bias",
      "blocks.10.mlp.fc1.bias",
      "blocks.10.mlp.fc2.bias"
    ],
    "lr_scale": 0.002403183829162165
  },
  "layer_11_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.10.attn.relative_position_bias_table",
      "blocks.10.attn.qkv.weight",
      "blocks.10.attn.proj.weight",
      "blocks.10.mlp.fc1.weight",
      "blocks.10.mlp.fc2.weight"
    ],
    "lr_scale": 0.002403183829162165
  },
  "layer_12_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.11.gamma_1",
      "blocks.11.gamma_2",
      "blocks.11.norm1.weight",
      "blocks.11.norm1.bias",
      "blocks.11.attn.q_bias",
      "blocks.11.attn.v_bias",
      "blocks.11.attn.proj.bias",
      "blocks.11.norm2.weight",
      "blocks.11.norm2.bias",
      "blocks.11.mlp.fc1.bias",
      "blocks.11.mlp.fc2.bias"
    ],
    "lr_scale": 0.003697205891018715
  },
  "layer_12_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.11.attn.relative_position_bias_table",
      "blocks.11.attn.qkv.weight",
      "blocks.11.attn.proj.weight",
      "blocks.11.mlp.fc1.weight",
      "blocks.11.mlp.fc2.weight"
    ],
    "lr_scale": 0.003697205891018715
  },
  "layer_13_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.12.gamma_1",
      "blocks.12.gamma_2",
      "blocks.12.norm1.weight",
      "blocks.12.norm1.bias",
      "blocks.12.attn.q_bias",
      "blocks.12.attn.v_bias",
      "blocks.12.attn.proj.bias",
      "blocks.12.norm2.weight",
      "blocks.12.norm2.bias",
      "blocks.12.mlp.fc1.bias",
      "blocks.12.mlp.fc2.bias"
    ],
    "lr_scale": 0.005688009063105715
  },
  "layer_13_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.12.attn.relative_position_bias_table",
      "blocks.12.attn.qkv.weight",
      "blocks.12.attn.proj.weight",
      "blocks.12.mlp.fc1.weight",
      "blocks.12.mlp.fc2.weight"
    ],
    "lr_scale": 0.005688009063105715
  },
  "layer_14_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.13.gamma_1",
      "blocks.13.gamma_2",
      "blocks.13.norm1.weight",
      "blocks.13.norm1.bias",
      "blocks.13.attn.q_bias",
      "blocks.13.attn.v_bias",
      "blocks.13.attn.proj.bias",
      "blocks.13.norm2.weight",
      "blocks.13.norm2.bias",
      "blocks.13.mlp.fc1.bias",
      "blocks.13.mlp.fc2.bias"
    ],
    "lr_scale": 0.008750783174008792
  },
  "layer_14_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.13.attn.relative_position_bias_table",
      "blocks.13.attn.qkv.weight",
      "blocks.13.attn.proj.weight",
      "blocks.13.mlp.fc1.weight",
      "blocks.13.mlp.fc2.weight"
    ],
    "lr_scale": 0.008750783174008792
  },
  "layer_15_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.14.gamma_1",
      "blocks.14.gamma_2",
      "blocks.14.norm1.weight",
      "blocks.14.norm1.bias",
      "blocks.14.attn.q_bias",
      "blocks.14.attn.v_bias",
      "blocks.14.attn.proj.bias",
      "blocks.14.norm2.weight",
      "blocks.14.norm2.bias",
      "blocks.14.mlp.fc1.bias",
      "blocks.14.mlp.fc2.bias"
    ],
    "lr_scale": 0.013462743344628911
  },
  "layer_15_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.14.attn.relative_position_bias_table",
      "blocks.14.attn.qkv.weight",
      "blocks.14.attn.proj.weight",
      "blocks.14.mlp.fc1.weight",
      "blocks.14.mlp.fc2.weight"
    ],
    "lr_scale": 0.013462743344628911
  },
  "layer_16_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.15.gamma_1",
      "blocks.15.gamma_2",
      "blocks.15.norm1.weight",
      "blocks.15.norm1.bias",
      "blocks.15.attn.q_bias",
      "blocks.15.attn.v_bias",
      "blocks.15.attn.proj.bias",
      "blocks.15.norm2.weight",
      "blocks.15.norm2.bias",
      "blocks.15.mlp.fc1.bias",
      "blocks.15.mlp.fc2.bias"
    ],
    "lr_scale": 0.02071191283789063
  },
  "layer_16_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.15.attn.relative_position_bias_table",
      "blocks.15.attn.qkv.weight",
      "blocks.15.attn.proj.weight",
      "blocks.15.mlp.fc1.weight",
      "blocks.15.mlp.fc2.weight"
    ],
    "lr_scale": 0.02071191283789063
  },
  "layer_17_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.16.gamma_1",
      "blocks.16.gamma_2",
      "blocks.16.norm1.weight",
      "blocks.16.norm1.bias",
      "blocks.16.attn.q_bias",
      "blocks.16.attn.v_bias",
      "blocks.16.attn.proj.bias",
      "blocks.16.norm2.weight",
      "blocks.16.norm2.bias",
      "blocks.16.mlp.fc1.bias",
      "blocks.16.mlp.fc2.bias"
    ],
    "lr_scale": 0.03186448128906251
  },
  "layer_17_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.16.attn.relative_position_bias_table",
      "blocks.16.attn.qkv.weight",
      "blocks.16.attn.proj.weight",
      "blocks.16.mlp.fc1.weight",
      "blocks.16.mlp.fc2.weight"
    ],
    "lr_scale": 0.03186448128906251
  },
  "layer_18_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.17.gamma_1",
      "blocks.17.gamma_2",
      "blocks.17.norm1.weight",
      "blocks.17.norm1.bias",
      "blocks.17.attn.q_bias",
      "blocks.17.attn.v_bias",
      "blocks.17.attn.proj.bias",
      "blocks.17.norm2.weight",
      "blocks.17.norm2.bias",
      "blocks.17.mlp.fc1.bias",
      "blocks.17.mlp.fc2.bias"
    ],
    "lr_scale": 0.049022278906250015
  },
  "layer_18_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.17.attn.relative_position_bias_table",
      "blocks.17.attn.qkv.weight",
      "blocks.17.attn.proj.weight",
      "blocks.17.mlp.fc1.weight",
      "blocks.17.mlp.fc2.weight"
    ],
    "lr_scale": 0.049022278906250015
  },
  "layer_19_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.18.gamma_1",
      "blocks.18.gamma_2",
      "blocks.18.norm1.weight",
      "blocks.18.norm1.bias",
      "blocks.18.attn.q_bias",
      "blocks.18.attn.v_bias",
      "blocks.18.attn.proj.bias",
      "blocks.18.norm2.weight",
      "blocks.18.norm2.bias",
      "blocks.18.mlp.fc1.bias",
      "blocks.18.mlp.fc2.bias"
    ],
    "lr_scale": 0.07541889062500001
  },
  "layer_19_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.18.attn.relative_position_bias_table",
      "blocks.18.attn.qkv.weight",
      "blocks.18.attn.proj.weight",
      "blocks.18.mlp.fc1.weight",
      "blocks.18.mlp.fc2.weight"
    ],
    "lr_scale": 0.07541889062500001
  },
  "layer_20_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.19.gamma_1",
      "blocks.19.gamma_2",
      "blocks.19.norm1.weight",
      "blocks.19.norm1.bias",
      "blocks.19.attn.q_bias",
      "blocks.19.attn.v_bias",
      "blocks.19.attn.proj.bias",
      "blocks.19.norm2.weight",
      "blocks.19.norm2.bias",
      "blocks.19.mlp.fc1.bias",
      "blocks.19.mlp.fc2.bias"
    ],
    "lr_scale": 0.11602906250000002
  },
  "layer_20_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.19.attn.relative_position_bias_table",
      "blocks.19.attn.qkv.weight",
      "blocks.19.attn.proj.weight",
      "blocks.19.mlp.fc1.weight",
      "blocks.19.mlp.fc2.weight"
    ],
    "lr_scale": 0.11602906250000002
  },
  "layer_21_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.20.gamma_1",
      "blocks.20.gamma_2",
      "blocks.20.norm1.weight",
      "blocks.20.norm1.bias",
      "blocks.20.attn.q_bias",
      "blocks.20.attn.v_bias",
      "blocks.20.attn.proj.bias",
      "blocks.20.norm2.weight",
      "blocks.20.norm2.bias",
      "blocks.20.mlp.fc1.bias",
      "blocks.20.mlp.fc2.bias"
    ],
    "lr_scale": 0.17850625000000003
  },
  "layer_21_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.20.attn.relative_position_bias_table",
      "blocks.20.attn.qkv.weight",
      "blocks.20.attn.proj.weight",
      "blocks.20.mlp.fc1.weight",
      "blocks.20.mlp.fc2.weight"
    ],
    "lr_scale": 0.17850625000000003
  },
  "layer_22_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.21.gamma_1",
      "blocks.21.gamma_2",
      "blocks.21.norm1.weight",
      "blocks.21.norm1.bias",
      "blocks.21.attn.q_bias",
      "blocks.21.attn.v_bias",
      "blocks.21.attn.proj.bias",
      "blocks.21.norm2.weight",
      "blocks.21.norm2.bias",
      "blocks.21.mlp.fc1.bias",
      "blocks.21.mlp.fc2.bias"
    ],
    "lr_scale": 0.274625
  },
  "layer_22_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.21.attn.relative_position_bias_table",
      "blocks.21.attn.qkv.weight",
      "blocks.21.attn.proj.weight",
      "blocks.21.mlp.fc1.weight",
      "blocks.21.mlp.fc2.weight"
    ],
    "lr_scale": 0.274625
  },
  "layer_23_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.22.gamma_1",
      "blocks.22.gamma_2",
      "blocks.22.norm1.weight",
      "blocks.22.norm1.bias",
      "blocks.22.attn.q_bias",
      "blocks.22.attn.v_bias",
      "blocks.22.attn.proj.bias",
      "blocks.22.norm2.weight",
      "blocks.22.norm2.bias",
      "blocks.22.mlp.fc1.bias",
      "blocks.22.mlp.fc2.bias"
    ],
    "lr_scale": 0.42250000000000004
  },
  "layer_23_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.22.attn.relative_position_bias_table",
      "blocks.22.attn.qkv.weight",
      "blocks.22.attn.proj.weight",
      "blocks.22.mlp.fc1.weight",
      "blocks.22.mlp.fc2.weight"
    ],
    "lr_scale": 0.42250000000000004
  },
  "layer_24_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "blocks.23.gamma_1",
      "blocks.23.gamma_2",
      "blocks.23.norm1.weight",
      "blocks.23.norm1.bias",
      "blocks.23.attn.q_bias",
      "blocks.23.attn.v_bias",
      "blocks.23.attn.proj.bias",
      "blocks.23.norm2.weight",
      "blocks.23.norm2.bias",
      "blocks.23.mlp.fc1.bias",
      "blocks.23.mlp.fc2.bias"
    ],
    "lr_scale": 0.65
  },
  "layer_24_decay": {
    "weight_decay": 0.05,
    "params": [
      "blocks.23.attn.relative_position_bias_table",
      "blocks.23.attn.qkv.weight",
      "blocks.23.attn.proj.weight",
      "blocks.23.mlp.fc1.weight",
      "blocks.23.mlp.fc2.weight"
    ],
    "lr_scale": 0.65
  },
  "layer_25_no_decay": {
    "weight_decay": 0.0,
    "params": [
      "fc_norm.weight",
      "fc_norm.bias",
      "head.bias"
    ],
    "lr_scale": 1.0
  },
  "layer_25_decay": {
    "weight_decay": 0.05,
    "params": [
      "head.weight"
    ],
    "lr_scale": 1.0
  }
}
/home/share/FM_Code/PanDerm/classification/furnace/utils.py:424: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()
Use step level LR scheduler!
Set warmup steps = 110
Set warmup steps = 0
Max WD = 0.0500000, Min WD = 0.0500000
criterion = SoftTargetCrossEntropy()
Start training for 50 epochs
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [0]  [ 0/11]  eta: 0:01:01  lr: 0.000000  min_lr: 0.000000  loss: 1.9459 (1.9459)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5211 (1.5211)  time: 5.5839  data: 3.5155  max mem: 37088
Epoch: [0]  [10/11]  eta: 0:00:01  lr: 0.000046  min_lr: 0.000000  loss: 1.9444 (1.9434)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5087 (1.5132)  time: 1.1896  data: 0.3197  max mem: 39406
Epoch: [0] Total time: 0:00:13 (1.2068 s / it)
2025-04-28 17:49:46 Averaged stats: lr: 0.000046  min_lr: 0.000000  loss: 1.9444 (1.9434)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5087 (1.5132)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:07    time: 3.8911  data: 3.0775  max mem: 39406
Test:  [1/2]  eta: 0:00:02    time: 2.1467  data: 1.5388  max mem: 39406
Test: Total time: 0:00:04 (2.2346 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.4090 Acc: 0.4971 Recall_macro: 0.4090 Recall_weighted: 0.4971 AUC-ROC: nan Weighted F1-score: 0.4645
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 0, 'Val Loss': 1.937660574913025, 'Val BAcc': np.float64(0.40902504683149843), 'Val Acc': 0.49709302325581395, 'Val ROC': np.float64(nan), 'Val W_F1': 0.4645174452018026, 'Val Recall_macro': 0.40902504683149843, 'Val Recall_weighted': 0.49709302325581395}
Max val mean accuracy: 0.50%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [1]  [ 0/11]  eta: 0:00:44  lr: 0.000050  min_lr: 0.000000  loss: 1.9342 (1.9342)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7310 (1.7310)  time: 4.0746  data: 3.3202  max mem: 39406
Epoch: [1]  [10/11]  eta: 0:00:01  lr: 0.000096  min_lr: 0.000000  loss: 1.9102 (1.9102)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9236 (1.9179)  time: 1.0609  data: 0.3019  max mem: 39406
Epoch: [1] Total time: 0:00:11 (1.0803 s / it)
2025-04-28 17:50:07 Averaged stats: lr: 0.000096  min_lr: 0.000000  loss: 1.9102 (1.9102)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9236 (1.9179)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4213  data: 3.0589  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8540  data: 1.5296  max mem: 39406
Test: Total time: 0:00:03 (1.9525 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.3199 Acc: 0.4651 Recall_macro: 0.3199 Recall_weighted: 0.4651 AUC-ROC: nan Weighted F1-score: 0.3456
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 1, 'Val Loss': 1.873509407043457, 'Val BAcc': np.float64(0.31990517203420427), 'Val Acc': 0.46511627906976744, 'Val ROC': np.float64(nan), 'Val W_F1': 0.3455830203604425, 'Val Recall_macro': 0.31990517203420427, 'Val Recall_weighted': 0.46511627906976744}
Max val mean accuracy: 0.50%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [2]  [ 0/11]  eta: 0:00:45  lr: 0.000101  min_lr: 0.000000  loss: 1.8723 (1.8723)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5615 (1.5615)  time: 4.1564  data: 3.3978  max mem: 39406
Epoch: [2]  [10/11]  eta: 0:00:01  lr: 0.000147  min_lr: 0.000000  loss: 1.8407 (1.8318)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7542 (1.7461)  time: 1.0752  data: 0.3090  max mem: 39406
Epoch: [2] Total time: 0:00:12 (1.0979 s / it)
2025-04-28 17:50:23 Averaged stats: lr: 0.000147  min_lr: 0.000000  loss: 1.8407 (1.8318)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7542 (1.7461)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:07    time: 3.5324  data: 3.1660  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.9107  data: 1.5830  max mem: 39406
Test: Total time: 0:00:04 (2.0191 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.3878 Acc: 0.1599 Recall_macro: 0.3878 Recall_weighted: 0.1599 AUC-ROC: nan Weighted F1-score: 0.0997
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 2, 'Val Loss': 1.7687667608261108, 'Val BAcc': np.float64(0.3877968877968878), 'Val Acc': 0.15988372093023256, 'Val ROC': np.float64(nan), 'Val W_F1': 0.0996645305183553, 'Val Recall_macro': 0.3877968877968878, 'Val Recall_weighted': 0.15988372093023256}
Max val mean accuracy: 0.50%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [3]  [ 0/11]  eta: 0:00:47  lr: 0.000151  min_lr: 0.000000  loss: 1.7769 (1.7769)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8985 (1.8985)  time: 4.3021  data: 3.5344  max mem: 39406
Epoch: [3]  [10/11]  eta: 0:00:01  lr: 0.000197  min_lr: 0.000000  loss: 1.6846 (1.6477)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1290 (2.2101)  time: 1.0954  data: 0.3214  max mem: 39406
Epoch: [3] Total time: 0:00:12 (1.1180 s / it)
2025-04-28 17:50:39 Averaged stats: lr: 0.000197  min_lr: 0.000000  loss: 1.6846 (1.6477)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1290 (2.2101)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:07    time: 3.7185  data: 3.3492  max mem: 39406
Test:  [1/2]  eta: 0:00:02    time: 2.0057  data: 1.6747  max mem: 39406
Test: Total time: 0:00:04 (2.1099 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.4771 Acc: 0.2820 Recall_macro: 0.4771 Recall_weighted: 0.2820 AUC-ROC: nan Weighted F1-score: 0.2714
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 3, 'Val Loss': 1.4527009725570679, 'Val BAcc': np.float64(0.4770939770939771), 'Val Acc': 0.2819767441860465, 'Val ROC': np.float64(nan), 'Val W_F1': 0.27137741579129526, 'Val Recall_macro': 0.4770939770939771, 'Val Recall_weighted': 0.2819767441860465}
Max val mean accuracy: 0.50%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [4]  [ 0/11]  eta: 0:00:44  lr: 0.000202  min_lr: 0.000000  loss: 1.5185 (1.5185)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0009 (2.0009)  time: 4.0562  data: 3.2829  max mem: 39406
Epoch: [4]  [10/11]  eta: 0:00:01  lr: 0.000248  min_lr: 0.000000  loss: 1.5279 (1.5465)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0887 (2.1400)  time: 1.0791  data: 0.2985  max mem: 39406
Epoch: [4] Total time: 0:00:12 (1.1004 s / it)
2025-04-28 17:50:56 Averaged stats: lr: 0.000248  min_lr: 0.000000  loss: 1.5279 (1.5465)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0887 (2.1400)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4151  data: 3.0414  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8541  data: 1.5208  max mem: 39406
Test: Total time: 0:00:03 (1.9545 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6105 Acc: 0.5116 Recall_macro: 0.6105 Recall_weighted: 0.5116 AUC-ROC: nan Weighted F1-score: 0.5514
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 4, 'Val Loss': 1.281982421875, 'Val BAcc': np.float64(0.6105462009978139), 'Val Acc': 0.5116279069767442, 'Val ROC': np.float64(nan), 'Val W_F1': 0.5513788687293747, 'Val Recall_macro': 0.6105462009978139, 'Val Recall_weighted': 0.5116279069767442}
Max val mean accuracy: 0.51%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [5]  [ 0/11]  eta: 0:00:46  lr: 0.000252  min_lr: 0.000000  loss: 1.3042 (1.3042)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1045 (2.1045)  time: 4.2032  data: 3.4241  max mem: 39406
Epoch: [5]  [10/11]  eta: 0:00:01  lr: 0.000298  min_lr: 0.000000  loss: 1.4654 (1.4724)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9561 (2.0468)  time: 1.0958  data: 0.3114  max mem: 39406
Epoch: [5] Total time: 0:00:12 (1.1160 s / it)
2025-04-28 17:51:18 Averaged stats: lr: 0.000298  min_lr: 0.000000  loss: 1.4654 (1.4724)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9561 (2.0468)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4744  data: 3.0987  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8859  data: 1.5494  max mem: 39406
Test: Total time: 0:00:04 (2.0049 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.5841 Acc: 0.4477 Recall_macro: 0.5841 Recall_weighted: 0.4477 AUC-ROC: nan Weighted F1-score: 0.4073
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 5, 'Val Loss': 1.181182861328125, 'Val BAcc': np.float64(0.584081267694171), 'Val Acc': 0.4476744186046512, 'Val ROC': np.float64(nan), 'Val W_F1': 0.40725432715400883, 'Val Recall_macro': 0.584081267694171, 'Val Recall_weighted': 0.4476744186046512}
Max val mean accuracy: 0.51%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [6]  [ 0/11]  eta: 0:00:46  lr: 0.000303  min_lr: 0.000000  loss: 1.4380 (1.4380)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5901 (1.5901)  time: 4.2051  data: 3.4232  max mem: 39406
Epoch: [6]  [10/11]  eta: 0:00:01  lr: 0.000349  min_lr: 0.000000  loss: 1.4081 (1.4088)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2063 (2.2378)  time: 1.1005  data: 0.3113  max mem: 39406
Epoch: [6] Total time: 0:00:12 (1.1226 s / it)
2025-04-28 17:51:34 Averaged stats: lr: 0.000349  min_lr: 0.000000  loss: 1.4081 (1.4088)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2063 (2.2378)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4687  data: 3.0921  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8837  data: 1.5461  max mem: 39406
Test: Total time: 0:00:04 (2.0019 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6326 Acc: 0.5378 Recall_macro: 0.6326 Recall_weighted: 0.5378 AUC-ROC: nan Weighted F1-score: 0.5347
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 6, 'Val Loss': 1.0472910404205322, 'Val BAcc': np.float64(0.6326395721234431), 'Val Acc': 0.5377906976744186, 'Val ROC': np.float64(nan), 'Val W_F1': 0.5346642251097917, 'Val Recall_macro': 0.6326395721234431, 'Val Recall_weighted': 0.5377906976744186}
Max val mean accuracy: 0.54%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [7]  [ 0/11]  eta: 0:00:44  lr: 0.000353  min_lr: 0.000000  loss: 1.3978 (1.3978)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5398 (1.5398)  time: 4.0814  data: 3.2982  max mem: 39406
Epoch: [7]  [10/11]  eta: 0:00:01  lr: 0.000399  min_lr: 0.000000  loss: 1.3480 (1.3605)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0111 (2.0577)  time: 1.0900  data: 0.2999  max mem: 39406
Epoch: [7] Total time: 0:00:12 (1.1120 s / it)
2025-04-28 17:51:57 Averaged stats: lr: 0.000399  min_lr: 0.000000  loss: 1.3480 (1.3605)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0111 (2.0577)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4506  data: 3.0730  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8748  data: 1.5366  max mem: 39406
Test: Total time: 0:00:03 (1.9851 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.7161 Acc: 0.6570 Recall_macro: 0.7161 Recall_weighted: 0.6570 AUC-ROC: nan Weighted F1-score: 0.6777
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 7, 'Val Loss': 1.0162723064422607, 'Val BAcc': np.float64(0.7160787129819388), 'Val Acc': 0.6569767441860465, 'Val ROC': np.float64(nan), 'Val W_F1': 0.6777308375156766, 'Val Recall_macro': 0.7160787129819388, 'Val Recall_weighted': 0.6569767441860465}
Max val mean accuracy: 0.66%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [8]  [ 0/11]  eta: 0:00:44  lr: 0.000404  min_lr: 0.000000  loss: 1.2810 (1.2810)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9632 (1.9632)  time: 4.0551  data: 3.2718  max mem: 39406
Epoch: [8]  [10/11]  eta: 0:00:01  lr: 0.000450  min_lr: 0.000000  loss: 1.4315 (1.4007)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0652 (2.2205)  time: 1.0874  data: 0.2975  max mem: 39406
Epoch: [8] Total time: 0:00:12 (1.1076 s / it)
2025-04-28 17:52:19 Averaged stats: lr: 0.000450  min_lr: 0.000000  loss: 1.4315 (1.4007)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0652 (2.2205)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3672  data: 2.9909  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8347  data: 1.4956  max mem: 39406
Test: Total time: 0:00:03 (1.9200 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6260 Acc: 0.5814 Recall_macro: 0.6260 Recall_weighted: 0.5814 AUC-ROC: nan Weighted F1-score: 0.5786
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 8, 'Val Loss': 1.0177685022354126, 'Val BAcc': np.float64(0.6259905150227731), 'Val Acc': 0.5813953488372093, 'Val ROC': np.float64(nan), 'Val W_F1': 0.5785829778820021, 'Val Recall_macro': 0.6259905150227731, 'Val Recall_weighted': 0.5813953488372093}
Max val mean accuracy: 0.66%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [9]  [ 0/11]  eta: 0:00:46  lr: 0.000454  min_lr: 0.000000  loss: 1.2000 (1.2000)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.5822 (2.5822)  time: 4.1970  data: 3.4080  max mem: 39406
Epoch: [9]  [10/11]  eta: 0:00:01  lr: 0.000500  min_lr: 0.000000  loss: 1.3935 (1.3939)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9900 (2.0277)  time: 1.1068  data: 0.3099  max mem: 39406
Epoch: [9] Total time: 0:00:12 (1.1293 s / it)
2025-04-28 17:52:35 Averaged stats: lr: 0.000500  min_lr: 0.000000  loss: 1.3935 (1.3939)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9900 (2.0277)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3801  data: 2.9999  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8420  data: 1.5000  max mem: 39406
Test: Total time: 0:00:03 (1.9356 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.5931 Acc: 0.5727 Recall_macro: 0.5931 Recall_weighted: 0.5727 AUC-ROC: nan Weighted F1-score: 0.5780
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 9, 'Val Loss': 1.0137192010879517, 'Val BAcc': np.float64(0.5930549619581877), 'Val Acc': 0.5726744186046512, 'Val ROC': np.float64(nan), 'Val W_F1': 0.5780015535653686, 'Val Recall_macro': 0.5930549619581877, 'Val Recall_weighted': 0.5726744186046512}
Max val mean accuracy: 0.66%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [10]  [ 0/11]  eta: 0:00:45  lr: 0.000500  min_lr: 0.000000  loss: 1.1741 (1.1741)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9866 (1.9866)  time: 4.1433  data: 3.3511  max mem: 39406
Epoch: [10]  [10/11]  eta: 0:00:01  lr: 0.000499  min_lr: 0.000000  loss: 1.5157 (1.4387)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1287 (2.3173)  time: 1.1043  data: 0.3047  max mem: 39406
Epoch: [10] Total time: 0:00:12 (1.1255 s / it)
2025-04-28 17:52:51 Averaged stats: lr: 0.000499  min_lr: 0.000000  loss: 1.5157 (1.4387)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1287 (2.3173)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3566  data: 2.9749  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8312  data: 1.4875  max mem: 39406
Test: Total time: 0:00:03 (1.9208 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6388 Acc: 0.7297 Recall_macro: 0.6388 Recall_weighted: 0.7297 AUC-ROC: nan Weighted F1-score: 0.7269
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 10, 'Val Loss': 0.92523193359375, 'Val BAcc': np.float64(0.6388436446500964), 'Val Acc': 0.7296511627906976, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7269301027409963, 'Val Recall_macro': 0.6388436446500964, 'Val Recall_weighted': 0.7296511627906976}
Max val mean accuracy: 0.73%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [11]  [ 0/11]  eta: 0:00:45  lr: 0.000499  min_lr: 0.000000  loss: 1.4389 (1.4389)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9790 (1.9790)  time: 4.0951  data: 3.3067  max mem: 39406
Epoch: [11]  [10/11]  eta: 0:00:01  lr: 0.000497  min_lr: 0.000000  loss: 1.4393 (1.3827)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4215 (2.2537)  time: 1.0963  data: 0.3007  max mem: 39406
Epoch: [11] Total time: 0:00:12 (1.1139 s / it)
2025-04-28 17:53:13 Averaged stats: lr: 0.000497  min_lr: 0.000000  loss: 1.4393 (1.3827)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4215 (2.2537)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3822  data: 3.0032  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8430  data: 1.5017  max mem: 39406
Test: Total time: 0:00:03 (1.9337 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6411 Acc: 0.6977 Recall_macro: 0.6411 Recall_weighted: 0.6977 AUC-ROC: nan Weighted F1-score: 0.7036
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 11, 'Val Loss': 0.9523974061012268, 'Val BAcc': np.float64(0.6410838924387312), 'Val Acc': 0.6976744186046512, 'Val ROC': np.float64(nan), 'Val W_F1': 0.703644108832912, 'Val Recall_macro': 0.6410838924387312, 'Val Recall_weighted': 0.6976744186046512}
Max val mean accuracy: 0.73%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [12]  [ 0/11]  eta: 0:00:43  lr: 0.000497  min_lr: 0.000000  loss: 1.3391 (1.3391)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.9705 (2.9705)  time: 3.9896  data: 3.1955  max mem: 39406
Epoch: [12]  [10/11]  eta: 0:00:01  lr: 0.000494  min_lr: 0.000000  loss: 1.1774 (1.2327)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9061 (2.1066)  time: 1.0920  data: 0.2906  max mem: 39406
Epoch: [12] Total time: 0:00:12 (1.1092 s / it)
2025-04-28 17:53:29 Averaged stats: lr: 0.000494  min_lr: 0.000000  loss: 1.1774 (1.2327)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9061 (2.1066)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3911  data: 3.0053  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8493  data: 1.5027  max mem: 39406
Test: Total time: 0:00:03 (1.9490 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6715 Acc: 0.6802 Recall_macro: 0.6715 Recall_weighted: 0.6802 AUC-ROC: nan Weighted F1-score: 0.6996
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 12, 'Val Loss': 0.8832847476005554, 'Val BAcc': np.float64(0.6714589109427819), 'Val Acc': 0.6802325581395349, 'Val ROC': np.float64(nan), 'Val W_F1': 0.6995651924948383, 'Val Recall_macro': 0.6714589109427819, 'Val Recall_weighted': 0.6802325581395349}
Max val mean accuracy: 0.73%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [13]  [ 0/11]  eta: 0:00:43  lr: 0.000493  min_lr: 0.000000  loss: 1.5673 (1.5673)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.9994 (2.9994)  time: 3.9907  data: 3.1924  max mem: 39406
Epoch: [13]  [10/11]  eta: 0:00:01  lr: 0.000488  min_lr: 0.000000  loss: 1.4075 (1.2968)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9838 (2.0913)  time: 1.0953  data: 0.2903  max mem: 39406
Epoch: [13] Total time: 0:00:12 (1.1126 s / it)
2025-04-28 17:53:46 Averaged stats: lr: 0.000488  min_lr: 0.000000  loss: 1.4075 (1.2968)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9838 (2.0913)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4352  data: 3.0547  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8709  data: 1.5274  max mem: 39406
Test: Total time: 0:00:03 (1.9825 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.7127 Acc: 0.6599 Recall_macro: 0.7127 Recall_weighted: 0.6599 AUC-ROC: nan Weighted F1-score: 0.6788
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 13, 'Val Loss': 0.880983829498291, 'Val BAcc': np.float64(0.7126958563087596), 'Val Acc': 0.6598837209302325, 'Val ROC': np.float64(nan), 'Val W_F1': 0.678834406400548, 'Val Recall_macro': 0.7126958563087596, 'Val Recall_weighted': 0.6598837209302325}
Max val mean accuracy: 0.73%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [14]  [ 0/11]  eta: 0:00:44  lr: 0.000488  min_lr: 0.000000  loss: 1.1897 (1.1897)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8631 (1.8631)  time: 4.0062  data: 3.2089  max mem: 39406
Epoch: [14]  [10/11]  eta: 0:00:01  lr: 0.000482  min_lr: 0.000000  loss: 1.1395 (1.1553)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1527 (2.1322)  time: 1.0971  data: 0.2918  max mem: 39406
Epoch: [14] Total time: 0:00:12 (1.1182 s / it)
2025-04-28 17:54:02 Averaged stats: lr: 0.000482  min_lr: 0.000000  loss: 1.1395 (1.1553)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1527 (2.1322)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4465  data: 3.0631  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8765  data: 1.5316  max mem: 39406
Test: Total time: 0:00:03 (1.9827 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6713 Acc: 0.6948 Recall_macro: 0.6713 Recall_weighted: 0.6948 AUC-ROC: nan Weighted F1-score: 0.7010
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 14, 'Val Loss': 0.8087230324745178, 'Val BAcc': np.float64(0.671255602481409), 'Val Acc': 0.6947674418604651, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7010198130576417, 'Val Recall_macro': 0.671255602481409, 'Val Recall_weighted': 0.6947674418604651}
Max val mean accuracy: 0.73%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [15]  [ 0/11]  eta: 0:00:46  lr: 0.000481  min_lr: 0.000000  loss: 1.5602 (1.5602)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.0642 (3.0642)  time: 4.2092  data: 3.4078  max mem: 39406
Epoch: [15]  [10/11]  eta: 0:00:01  lr: 0.000474  min_lr: 0.000000  loss: 1.4861 (1.4343)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.8493 (2.6389)  time: 1.1172  data: 0.3099  max mem: 39406
Epoch: [15] Total time: 0:00:12 (1.1359 s / it)
2025-04-28 17:54:18 Averaged stats: lr: 0.000474  min_lr: 0.000000  loss: 1.4861 (1.4343)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.8493 (2.6389)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3704  data: 2.9839  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8389  data: 1.4920  max mem: 39406
Test: Total time: 0:00:03 (1.9398 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.7297 Acc: 0.7384 Recall_macro: 0.7297 Recall_weighted: 0.7384 AUC-ROC: nan Weighted F1-score: 0.7550
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 15, 'Val Loss': 0.8559160828590393, 'Val BAcc': np.float64(0.7296719928977993), 'Val Acc': 0.7383720930232558, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7550452986156653, 'Val Recall_macro': 0.7296719928977993, 'Val Recall_weighted': 0.7383720930232558}
Max val mean accuracy: 0.74%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [16]  [ 0/11]  eta: 0:00:43  lr: 0.000473  min_lr: 0.000000  loss: 1.3143 (1.3143)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.7080 (2.7080)  time: 3.9608  data: 3.1710  max mem: 39406
Epoch: [16]  [10/11]  eta: 0:00:01  lr: 0.000464  min_lr: 0.000000  loss: 1.4089 (1.3912)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2370 (2.1514)  time: 1.0890  data: 0.2884  max mem: 39406
Epoch: [16] Total time: 0:00:12 (1.1108 s / it)
2025-04-28 17:54:40 Averaged stats: lr: 0.000464  min_lr: 0.000000  loss: 1.4089 (1.3912)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2370 (2.1514)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3859  data: 3.0031  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8453  data: 1.5016  max mem: 39406
Test: Total time: 0:00:03 (1.9417 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.7117 Acc: 0.7326 Recall_macro: 0.7117 Recall_weighted: 0.7326 AUC-ROC: nan Weighted F1-score: 0.7467
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 16, 'Val Loss': 0.8337876200675964, 'Val BAcc': np.float64(0.7117310657955819), 'Val Acc': 0.7325581395348837, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7467181276656369, 'Val Recall_macro': 0.7117310657955819, 'Val Recall_weighted': 0.7325581395348837}
Max val mean accuracy: 0.74%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [17]  [ 0/11]  eta: 0:00:44  lr: 0.000463  min_lr: 0.000000  loss: 1.3237 (1.3237)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.1065 (2.1065)  time: 4.0172  data: 3.2211  max mem: 39406
Epoch: [17]  [10/11]  eta: 0:00:01  lr: 0.000453  min_lr: 0.000000  loss: 1.3509 (1.2892)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6119 (1.6722)  time: 1.1033  data: 0.2929  max mem: 39406
Epoch: [17] Total time: 0:00:12 (1.1272 s / it)
2025-04-28 17:54:57 Averaged stats: lr: 0.000453  min_lr: 0.000000  loss: 1.3509 (1.2892)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6119 (1.6722)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4630  data: 3.0790  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8853  data: 1.5395  max mem: 39406
Test: Total time: 0:00:04 (2.0012 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.7198 Acc: 0.7791 Recall_macro: 0.7198 Recall_weighted: 0.7791 AUC-ROC: nan Weighted F1-score: 0.7733
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 17, 'Val Loss': 0.7361859679222107, 'Val BAcc': np.float64(0.7198403229370972), 'Val Acc': 0.7790697674418605, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7732523057227564, 'Val Recall_macro': 0.7198403229370972, 'Val Recall_weighted': 0.7790697674418605}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [18]  [ 0/11]  eta: 0:00:44  lr: 0.000452  min_lr: 0.000000  loss: 1.5969 (1.5969)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.4918 (3.4918)  time: 4.0532  data: 3.2635  max mem: 39406
Epoch: [18]  [10/11]  eta: 0:00:01  lr: 0.000441  min_lr: 0.000000  loss: 1.4363 (1.3802)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8984 (2.0803)  time: 1.0966  data: 0.2968  max mem: 39406
Epoch: [18] Total time: 0:00:12 (1.1175 s / it)
2025-04-28 17:55:19 Averaged stats: lr: 0.000441  min_lr: 0.000000  loss: 1.4363 (1.3802)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8984 (2.0803)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:07    time: 3.5261  data: 3.1406  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.9153  data: 1.5704  max mem: 39406
Test: Total time: 0:00:04 (2.0082 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.7143 Acc: 0.7442 Recall_macro: 0.7143 Recall_weighted: 0.7442 AUC-ROC: nan Weighted F1-score: 0.7530
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 18, 'Val Loss': 0.7898166179656982, 'Val BAcc': np.float64(0.7142567989019603), 'Val Acc': 0.7441860465116279, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7530426835715202, 'Val Recall_macro': 0.7142567989019603, 'Val Recall_weighted': 0.7441860465116279}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [19]  [ 0/11]  eta: 0:00:44  lr: 0.000440  min_lr: 0.000000  loss: 1.4334 (1.4334)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5106 (1.5106)  time: 4.0044  data: 3.2086  max mem: 39406
Epoch: [19]  [10/11]  eta: 0:00:01  lr: 0.000428  min_lr: 0.000000  loss: 1.4334 (1.3782)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9777 (1.9645)  time: 1.0964  data: 0.2918  max mem: 39406
Epoch: [19] Total time: 0:00:12 (1.1190 s / it)
2025-04-28 17:55:35 Averaged stats: lr: 0.000428  min_lr: 0.000000  loss: 1.4334 (1.3782)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9777 (1.9645)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3799  data: 2.9939  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8434  data: 1.4970  max mem: 39406
Test: Total time: 0:00:03 (1.9450 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6544 Acc: 0.6628 Recall_macro: 0.6544 Recall_weighted: 0.6628 AUC-ROC: nan Weighted F1-score: 0.6929
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 19, 'Val Loss': 0.8912915587425232, 'Val BAcc': np.float64(0.6543759914082495), 'Val Acc': 0.6627906976744186, 'Val ROC': np.float64(nan), 'Val W_F1': 0.692874748180207, 'Val Recall_macro': 0.6543759914082495, 'Val Recall_weighted': 0.6627906976744186}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [20]  [ 0/11]  eta: 0:00:46  lr: 0.000427  min_lr: 0.000000  loss: 1.4637 (1.4637)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.4301 (2.4301)  time: 4.2163  data: 3.4203  max mem: 39406
Epoch: [20]  [10/11]  eta: 0:00:01  lr: 0.000414  min_lr: 0.000000  loss: 1.3582 (1.3173)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0077 (2.1032)  time: 1.1179  data: 0.3110  max mem: 39406
Epoch: [20] Total time: 0:00:12 (1.1390 s / it)
2025-04-28 17:55:52 Averaged stats: lr: 0.000414  min_lr: 0.000000  loss: 1.3582 (1.3173)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0077 (2.1032)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3123  data: 2.9251  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8106  data: 1.4626  max mem: 39406
Test: Total time: 0:00:03 (1.9169 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6475 Acc: 0.7645 Recall_macro: 0.6475 Recall_weighted: 0.7645 AUC-ROC: nan Weighted F1-score: 0.7574
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 20, 'Val Loss': 0.7501975893974304, 'Val BAcc': np.float64(0.647529733336185), 'Val Acc': 0.7645348837209303, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7573873959933471, 'Val Recall_macro': 0.647529733336185, 'Val Recall_weighted': 0.7645348837209303}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [21]  [ 0/11]  eta: 0:00:44  lr: 0.000413  min_lr: 0.000000  loss: 1.3940 (1.3940)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.5210 (2.5210)  time: 4.0659  data: 3.2650  max mem: 39406
Epoch: [21]  [10/11]  eta: 0:00:01  lr: 0.000399  min_lr: 0.000000  loss: 0.9904 (1.1497)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2290 (2.0462)  time: 1.1062  data: 0.2969  max mem: 39406
Epoch: [21] Total time: 0:00:12 (1.1304 s / it)
2025-04-28 17:56:08 Averaged stats: lr: 0.000399  min_lr: 0.000000  loss: 0.9904 (1.1497)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2290 (2.0462)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3680  data: 2.9776  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8382  data: 1.4889  max mem: 39406
Test: Total time: 0:00:03 (1.9527 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.7069 Acc: 0.7733 Recall_macro: 0.7069 Recall_weighted: 0.7733 AUC-ROC: nan Weighted F1-score: 0.7711
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 21, 'Val Loss': 0.7196229696273804, 'Val BAcc': np.float64(0.7068874354035645), 'Val Acc': 0.7732558139534884, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7710582314060257, 'Val Recall_macro': 0.7068874354035645, 'Val Recall_weighted': 0.7732558139534884}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [22]  [ 0/11]  eta: 0:00:43  lr: 0.000397  min_lr: 0.000000  loss: 1.1546 (1.1546)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7577 (1.7577)  time: 3.9772  data: 3.1756  max mem: 39406
Epoch: [22]  [10/11]  eta: 0:00:01  lr: 0.000382  min_lr: 0.000000  loss: 1.1546 (1.1906)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9554 (2.1473)  time: 1.0985  data: 0.2888  max mem: 39406
Epoch: [22] Total time: 0:00:12 (1.1174 s / it)
2025-04-28 17:56:24 Averaged stats: lr: 0.000382  min_lr: 0.000000  loss: 1.1546 (1.1906)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9554 (2.1473)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3637  data: 2.9737  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8368  data: 1.4869  max mem: 39406
Test: Total time: 0:00:03 (1.9270 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6938 Acc: 0.7703 Recall_macro: 0.6938 Recall_weighted: 0.7703 AUC-ROC: nan Weighted F1-score: 0.7750
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 22, 'Val Loss': 0.7168727517127991, 'Val BAcc': np.float64(0.6937811091359478), 'Val Acc': 0.7703488372093024, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7750156072414932, 'Val Recall_macro': 0.6937811091359478, 'Val Recall_weighted': 0.7703488372093024}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [23]  [ 0/11]  eta: 0:00:45  lr: 0.000381  min_lr: 0.000000  loss: 1.4817 (1.4817)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0787 (2.0787)  time: 4.1255  data: 3.3232  max mem: 39406
Epoch: [23]  [10/11]  eta: 0:00:01  lr: 0.000365  min_lr: 0.000000  loss: 1.3808 (1.2949)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9697 (2.0039)  time: 1.1133  data: 0.3022  max mem: 39406
Epoch: [23] Total time: 0:00:12 (1.1332 s / it)
2025-04-28 17:56:41 Averaged stats: lr: 0.000365  min_lr: 0.000000  loss: 1.3808 (1.2949)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9697 (2.0039)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:07    time: 3.5478  data: 3.1571  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.9286  data: 1.5786  max mem: 39406
Test: Total time: 0:00:04 (2.0457 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6535 Acc: 0.7849 Recall_macro: 0.6535 Recall_weighted: 0.7849 AUC-ROC: nan Weighted F1-score: 0.7668
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 23, 'Val Loss': 0.7255517840385437, 'Val BAcc': np.float64(0.6535445978026623), 'Val Acc': 0.7848837209302325, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7667646396267517, 'Val Recall_macro': 0.6535445978026623, 'Val Recall_weighted': 0.7848837209302325}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [24]  [ 0/11]  eta: 0:00:46  lr: 0.000364  min_lr: 0.000000  loss: 0.9734 (0.9734)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8134 (1.8134)  time: 4.2037  data: 3.4105  max mem: 39406
Epoch: [24]  [10/11]  eta: 0:00:01  lr: 0.000348  min_lr: 0.000000  loss: 1.1585 (1.1482)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8136 (2.0265)  time: 1.1121  data: 0.3101  max mem: 39406
Epoch: [24] Total time: 0:00:12 (1.1333 s / it)
2025-04-28 17:57:04 Averaged stats: lr: 0.000348  min_lr: 0.000000  loss: 1.1585 (1.1482)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8136 (2.0265)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3893  data: 3.0070  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8473  data: 1.5036  max mem: 39406
Test: Total time: 0:00:03 (1.9359 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6372 Acc: 0.7791 Recall_macro: 0.6372 Recall_weighted: 0.7791 AUC-ROC: nan Weighted F1-score: 0.7685
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 24, 'Val Loss': 0.6934409141540527, 'Val BAcc': np.float64(0.6372112137273428), 'Val Acc': 0.7790697674418605, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7685329748537223, 'Val Recall_macro': 0.6372112137273428, 'Val Recall_weighted': 0.7790697674418605}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [25]  [ 0/11]  eta: 0:00:43  lr: 0.000346  min_lr: 0.000000  loss: 0.8646 (0.8646)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7506 (1.7506)  time: 3.9970  data: 3.2015  max mem: 39406
Epoch: [25]  [10/11]  eta: 0:00:01  lr: 0.000329  min_lr: 0.000000  loss: 1.1686 (1.0679)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9637 (1.8645)  time: 1.0971  data: 0.2911  max mem: 39406
Epoch: [25] Total time: 0:00:12 (1.1170 s / it)
2025-04-28 17:57:20 Averaged stats: lr: 0.000329  min_lr: 0.000000  loss: 1.1686 (1.0679)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9637 (1.8645)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:07    time: 3.5278  data: 3.1412  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.9178  data: 1.5707  max mem: 39406
Test: Total time: 0:00:04 (2.0255 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.7226 Acc: 0.7849 Recall_macro: 0.7226 Recall_weighted: 0.7849 AUC-ROC: nan Weighted F1-score: 0.7881
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 25, 'Val Loss': 0.7370926737785339, 'Val BAcc': np.float64(0.7225807927743411), 'Val Acc': 0.7848837209302325, 'Val ROC': np.float64(nan), 'Val W_F1': 0.788111507249679, 'Val Recall_macro': 0.7225807927743411, 'Val Recall_weighted': 0.7848837209302325}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [26]  [ 0/11]  eta: 0:00:45  lr: 0.000328  min_lr: 0.000000  loss: 1.6624 (1.6624)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.8524 (3.8524)  time: 4.1448  data: 3.3449  max mem: 39406
Epoch: [26]  [10/11]  eta: 0:00:01  lr: 0.000310  min_lr: 0.000000  loss: 1.1940 (1.1945)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9630 (2.1060)  time: 1.1126  data: 0.3042  max mem: 39406
Epoch: [26] Total time: 0:00:12 (1.1341 s / it)
2025-04-28 17:57:37 Averaged stats: lr: 0.000310  min_lr: 0.000000  loss: 1.1940 (1.1945)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9630 (2.1060)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4123  data: 3.0249  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8606  data: 1.5125  max mem: 39406
Test: Total time: 0:00:03 (1.9630 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6685 Acc: 0.7733 Recall_macro: 0.6685 Recall_weighted: 0.7733 AUC-ROC: nan Weighted F1-score: 0.7664
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 26, 'Val Loss': 0.7145064473152161, 'Val BAcc': np.float64(0.668474054280506), 'Val Acc': 0.7732558139534884, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7664158543176558, 'Val Recall_macro': 0.668474054280506, 'Val Recall_weighted': 0.7732558139534884}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [27]  [ 0/11]  eta: 0:00:46  lr: 0.000309  min_lr: 0.000000  loss: 1.1492 (1.1492)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3988 (1.3988)  time: 4.2627  data: 3.4636  max mem: 39406
Epoch: [27]  [10/11]  eta: 0:00:01  lr: 0.000291  min_lr: 0.000000  loss: 1.0615 (1.1168)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8480 (1.9475)  time: 1.1220  data: 0.3149  max mem: 39406
Epoch: [27] Total time: 0:00:12 (1.1433 s / it)
2025-04-28 17:57:53 Averaged stats: lr: 0.000291  min_lr: 0.000000  loss: 1.0615 (1.1168)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8480 (1.9475)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4434  data: 3.0587  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8766  data: 1.5294  max mem: 39406
Test: Total time: 0:00:03 (1.9717 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6597 Acc: 0.7733 Recall_macro: 0.6597 Recall_weighted: 0.7733 AUC-ROC: nan Weighted F1-score: 0.7641
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 27, 'Val Loss': 0.7103608846664429, 'Val BAcc': np.float64(0.6597048628016371), 'Val Acc': 0.7732558139534884, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7641294268201549, 'Val Recall_macro': 0.6597048628016371, 'Val Recall_weighted': 0.7732558139534884}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [28]  [ 0/11]  eta: 0:00:44  lr: 0.000290  min_lr: 0.000000  loss: 1.2165 (1.2165)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7157 (1.7157)  time: 4.0511  data: 3.2526  max mem: 39406
Epoch: [28]  [10/11]  eta: 0:00:01  lr: 0.000272  min_lr: 0.000000  loss: 1.1616 (1.1444)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8333 (1.8676)  time: 1.1030  data: 0.2958  max mem: 39406
Epoch: [28] Total time: 0:00:12 (1.1269 s / it)
2025-04-28 17:58:10 Averaged stats: lr: 0.000272  min_lr: 0.000000  loss: 1.1616 (1.1444)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8333 (1.8676)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4580  data: 3.0723  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8829  data: 1.5362  max mem: 39406
Test: Total time: 0:00:03 (1.9868 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6750 Acc: 0.7791 Recall_macro: 0.6750 Recall_weighted: 0.7791 AUC-ROC: nan Weighted F1-score: 0.7738
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 28, 'Val Loss': 0.703216552734375, 'Val BAcc': np.float64(0.6749573301831365), 'Val Acc': 0.7790697674418605, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7737711632029307, 'Val Recall_macro': 0.6749573301831365, 'Val Recall_weighted': 0.7790697674418605}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [29]  [ 0/11]  eta: 0:00:44  lr: 0.000270  min_lr: 0.000000  loss: 0.6760 (0.6760)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6897 (1.6897)  time: 4.0681  data: 3.2689  max mem: 39406
Epoch: [29]  [10/11]  eta: 0:00:01  lr: 0.000252  min_lr: 0.000000  loss: 1.2890 (1.1289)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0531 (2.0027)  time: 1.1064  data: 0.2973  max mem: 39406
Epoch: [29] Total time: 0:00:12 (1.1286 s / it)
2025-04-28 17:58:26 Averaged stats: lr: 0.000252  min_lr: 0.000000  loss: 1.2890 (1.1289)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0531 (2.0027)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3883  data: 3.0021  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8481  data: 1.5011  max mem: 39406
Test: Total time: 0:00:03 (1.9435 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6913 Acc: 0.7471 Recall_macro: 0.6913 Recall_weighted: 0.7471 AUC-ROC: nan Weighted F1-score: 0.7508
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 29, 'Val Loss': 0.6828990578651428, 'Val BAcc': np.float64(0.691269701205185), 'Val Acc': 0.747093023255814, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7508429243154627, 'Val Recall_macro': 0.691269701205185, 'Val Recall_weighted': 0.747093023255814}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [30]  [ 0/11]  eta: 0:00:44  lr: 0.000251  min_lr: 0.000000  loss: 1.2548 (1.2548)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9247 (1.9247)  time: 4.0340  data: 3.2346  max mem: 39406
Epoch: [30]  [10/11]  eta: 0:00:01  lr: 0.000233  min_lr: 0.000000  loss: 1.3026 (1.2207)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0808 (2.0267)  time: 1.1040  data: 0.2941  max mem: 39406
Epoch: [30] Total time: 0:00:12 (1.1272 s / it)
2025-04-28 17:58:42 Averaged stats: lr: 0.000233  min_lr: 0.000000  loss: 1.3026 (1.2207)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0808 (2.0267)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:07    time: 3.7070  data: 3.3202  max mem: 39406
Test:  [1/2]  eta: 0:00:02    time: 2.0088  data: 1.6602  max mem: 39406
Test: Total time: 0:00:04 (2.1179 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6806 Acc: 0.7820 Recall_macro: 0.6806 Recall_weighted: 0.7820 AUC-ROC: nan Weighted F1-score: 0.7796
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 30, 'Val Loss': 0.6624563336372375, 'Val BAcc': np.float64(0.6806222745577584), 'Val Acc': 0.7819767441860465, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7795668139877611, 'Val Recall_macro': 0.6806222745577584, 'Val Recall_weighted': 0.7819767441860465}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [31]  [ 0/11]  eta: 0:00:45  lr: 0.000231  min_lr: 0.000000  loss: 1.4894 (1.4894)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.3089 (2.3089)  time: 4.1437  data: 3.3428  max mem: 39406
Epoch: [31]  [10/11]  eta: 0:00:01  lr: 0.000213  min_lr: 0.000000  loss: 1.3298 (1.2614)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8455 (1.9226)  time: 1.1138  data: 0.3040  max mem: 39406
Epoch: [31] Total time: 0:00:12 (1.1345 s / it)
2025-04-28 17:58:59 Averaged stats: lr: 0.000213  min_lr: 0.000000  loss: 1.3298 (1.2614)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8455 (1.9226)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4094  data: 3.0211  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8587  data: 1.5106  max mem: 39406
Test: Total time: 0:00:03 (1.9545 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6498 Acc: 0.7733 Recall_macro: 0.6498 Recall_weighted: 0.7733 AUC-ROC: nan Weighted F1-score: 0.7558
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 31, 'Val Loss': 0.6767112612724304, 'Val BAcc': np.float64(0.6497823940404586), 'Val Acc': 0.7732558139534884, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7557945117449514, 'Val Recall_macro': 0.6497823940404586, 'Val Recall_weighted': 0.7732558139534884}
Max val mean accuracy: 0.78%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [32]  [ 0/11]  eta: 0:00:44  lr: 0.000211  min_lr: 0.000000  loss: 1.3528 (1.3528)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8578 (1.8578)  time: 4.0449  data: 3.2430  max mem: 39406
Epoch: [32]  [10/11]  eta: 0:00:01  lr: 0.000194  min_lr: 0.000000  loss: 1.3048 (1.2739)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8578 (1.8377)  time: 1.1054  data: 0.2949  max mem: 39406
Epoch: [32] Total time: 0:00:12 (1.1292 s / it)
2025-04-28 17:59:15 Averaged stats: lr: 0.000194  min_lr: 0.000000  loss: 1.3048 (1.2739)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8578 (1.8377)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4479  data: 3.0573  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8777  data: 1.5287  max mem: 39406
Test: Total time: 0:00:03 (1.9789 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.7012 Acc: 0.8023 Recall_macro: 0.7012 Recall_weighted: 0.8023 AUC-ROC: nan Weighted F1-score: 0.7964
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 32, 'Val Loss': 0.6637159585952759, 'Val BAcc': np.float64(0.701154859090343), 'Val Acc': 0.8023255813953488, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7963590894179688, 'Val Recall_macro': 0.701154859090343, 'Val Recall_weighted': 0.8023255813953488}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [33]  [ 0/11]  eta: 0:00:44  lr: 0.000192  min_lr: 0.000000  loss: 0.6826 (0.6826)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4395 (1.4395)  time: 4.0663  data: 3.2743  max mem: 39406
Epoch: [33]  [10/11]  eta: 0:00:01  lr: 0.000175  min_lr: 0.000000  loss: 1.0056 (1.0693)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8674 (1.8904)  time: 1.0988  data: 0.2977  max mem: 39406
Epoch: [33] Total time: 0:00:12 (1.1204 s / it)
2025-04-28 17:59:38 Averaged stats: lr: 0.000175  min_lr: 0.000000  loss: 1.0056 (1.0693)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8674 (1.8904)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3459  data: 2.9608  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8257  data: 1.4805  max mem: 39406
Test: Total time: 0:00:03 (1.9347 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6767 Acc: 0.7791 Recall_macro: 0.6767 Recall_weighted: 0.7791 AUC-ROC: nan Weighted F1-score: 0.7728
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 33, 'Val Loss': 0.6860688924789429, 'Val BAcc': np.float64(0.6766593891755183), 'Val Acc': 0.7790697674418605, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7728311007295048, 'Val Recall_macro': 0.6766593891755183, 'Val Recall_weighted': 0.7790697674418605}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [34]  [ 0/11]  eta: 0:00:45  lr: 0.000173  min_lr: 0.000000  loss: 1.1696 (1.1696)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8043 (1.8043)  time: 4.1516  data: 3.3572  max mem: 39406
Epoch: [34]  [10/11]  eta: 0:00:01  lr: 0.000157  min_lr: 0.000000  loss: 1.1696 (1.1071)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7680 (1.7988)  time: 1.1117  data: 0.3053  max mem: 39406
Epoch: [34] Total time: 0:00:12 (1.1327 s / it)
2025-04-28 17:59:55 Averaged stats: lr: 0.000157  min_lr: 0.000000  loss: 1.1696 (1.1071)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7680 (1.7988)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3569  data: 2.9754  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8321  data: 1.4878  max mem: 39406
Test: Total time: 0:00:03 (1.9313 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6584 Acc: 0.7878 Recall_macro: 0.6584 Recall_weighted: 0.7878 AUC-ROC: nan Weighted F1-score: 0.7800
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 34, 'Val Loss': 0.6832404136657715, 'Val BAcc': np.float64(0.6583913096171161), 'Val Acc': 0.7877906976744186, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7800025592260532, 'Val Recall_macro': 0.6583913096171161, 'Val Recall_weighted': 0.7877906976744186}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [35]  [ 0/11]  eta: 0:00:44  lr: 0.000155  min_lr: 0.000000  loss: 1.4754 (1.4754)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 3.4407 (3.4407)  time: 4.0812  data: 3.2831  max mem: 39406
Epoch: [35]  [10/11]  eta: 0:00:01  lr: 0.000139  min_lr: 0.000000  loss: 1.2796 (1.1877)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0900 (2.0491)  time: 1.1078  data: 0.2985  max mem: 39406
Epoch: [35] Total time: 0:00:12 (1.1287 s / it)
2025-04-28 18:00:11 Averaged stats: lr: 0.000139  min_lr: 0.000000  loss: 1.2796 (1.1877)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0900 (2.0491)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:07    time: 3.6291  data: 3.2443  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.9682  data: 1.6223  max mem: 39406
Test: Total time: 0:00:04 (2.0725 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6955 Acc: 0.7878 Recall_macro: 0.6955 Recall_weighted: 0.7878 AUC-ROC: nan Weighted F1-score: 0.7880
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 35, 'Val Loss': 0.6821730732917786, 'Val BAcc': np.float64(0.6954657095302257), 'Val Acc': 0.7877906976744186, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7880403478402456, 'Val Recall_macro': 0.6954657095302257, 'Val Recall_weighted': 0.7877906976744186}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [36]  [ 0/11]  eta: 0:00:46  lr: 0.000137  min_lr: 0.000000  loss: 1.0520 (1.0520)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4563 (1.4563)  time: 4.2571  data: 3.4560  max mem: 39406
Epoch: [36]  [10/11]  eta: 0:00:01  lr: 0.000122  min_lr: 0.000000  loss: 1.1975 (1.1768)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7828 (1.7753)  time: 1.1252  data: 0.3143  max mem: 39406
Epoch: [36] Total time: 0:00:12 (1.1468 s / it)
2025-04-28 18:00:28 Averaged stats: lr: 0.000122  min_lr: 0.000000  loss: 1.1975 (1.1768)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7828 (1.7753)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4786  data: 3.0973  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8944  data: 1.5487  max mem: 39406
Test: Total time: 0:00:03 (1.9915 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6763 Acc: 0.7936 Recall_macro: 0.6763 Recall_weighted: 0.7936 AUC-ROC: nan Weighted F1-score: 0.7877
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 36, 'Val Loss': 0.6651089191436768, 'Val BAcc': np.float64(0.676252502187986), 'Val Acc': 0.7936046511627907, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7877244391918572, 'Val Recall_macro': 0.676252502187986, 'Val Recall_weighted': 0.7936046511627907}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [37]  [ 0/11]  eta: 0:00:45  lr: 0.000120  min_lr: 0.000000  loss: 1.3235 (1.3235)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7859 (1.7859)  time: 4.1795  data: 3.3805  max mem: 39406
Epoch: [37]  [10/11]  eta: 0:00:01  lr: 0.000105  min_lr: 0.000000  loss: 1.0783 (1.0673)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7575 (1.7370)  time: 1.1168  data: 0.3074  max mem: 39406
Epoch: [37] Total time: 0:00:12 (1.1340 s / it)
2025-04-28 18:00:44 Averaged stats: lr: 0.000105  min_lr: 0.000000  loss: 1.0783 (1.0673)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7575 (1.7370)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3932  data: 3.0056  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8517  data: 1.5029  max mem: 39406
Test: Total time: 0:00:03 (1.9443 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6712 Acc: 0.7820 Recall_macro: 0.6712 Recall_weighted: 0.7820 AUC-ROC: nan Weighted F1-score: 0.7792
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 37, 'Val Loss': 0.6706639528274536, 'Val BAcc': np.float64(0.6712450078901692), 'Val Acc': 0.7819767441860465, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7791783329267189, 'Val Recall_macro': 0.6712450078901692, 'Val Recall_weighted': 0.7819767441860465}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [38]  [ 0/11]  eta: 0:00:45  lr: 0.000104  min_lr: 0.000000  loss: 0.8199 (0.8199)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.2222 (1.2222)  time: 4.1782  data: 3.3788  max mem: 39406
Epoch: [38]  [10/11]  eta: 0:00:01  lr: 0.000090  min_lr: 0.000000  loss: 1.0347 (1.0318)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8041 (1.7730)  time: 1.1177  data: 0.3072  max mem: 39406
Epoch: [38] Total time: 0:00:12 (1.1406 s / it)
2025-04-28 18:01:01 Averaged stats: lr: 0.000090  min_lr: 0.000000  loss: 1.0347 (1.0318)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8041 (1.7730)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3786  data: 2.9927  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8438  data: 1.4964  max mem: 39406
Test: Total time: 0:00:03 (1.9438 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6960 Acc: 0.7907 Recall_macro: 0.6960 Recall_weighted: 0.7907 AUC-ROC: nan Weighted F1-score: 0.7872
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 38, 'Val Loss': 0.6676025390625, 'Val BAcc': np.float64(0.6959791966243579), 'Val Acc': 0.7906976744186046, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7871943901588042, 'Val Recall_macro': 0.6959791966243579, 'Val Recall_weighted': 0.7906976744186046}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [39]  [ 0/11]  eta: 0:00:44  lr: 0.000088  min_lr: 0.000000  loss: 1.3175 (1.3175)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5461 (1.5461)  time: 4.0442  data: 3.2408  max mem: 39406
Epoch: [39]  [10/11]  eta: 0:00:01  lr: 0.000075  min_lr: 0.000000  loss: 1.1967 (1.1205)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6832 (1.8283)  time: 1.1062  data: 0.2947  max mem: 39406
Epoch: [39] Total time: 0:00:12 (1.1232 s / it)
2025-04-28 18:01:17 Averaged stats: lr: 0.000075  min_lr: 0.000000  loss: 1.1967 (1.1205)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6832 (1.8283)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:07    time: 3.5297  data: 3.1402  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.9192  data: 1.5701  max mem: 39406
Test: Total time: 0:00:04 (2.0106 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6914 Acc: 0.7965 Recall_macro: 0.6914 Recall_weighted: 0.7965 AUC-ROC: nan Weighted F1-score: 0.7916
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 39, 'Val Loss': 0.666623592376709, 'Val BAcc': np.float64(0.6913901853256692), 'Val Acc': 0.7965116279069767, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7915558785629971, 'Val Recall_macro': 0.6913901853256692, 'Val Recall_weighted': 0.7965116279069767}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [40]  [ 0/11]  eta: 0:00:45  lr: 0.000074  min_lr: 0.000000  loss: 0.8911 (0.8911)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4513 (1.4513)  time: 4.1639  data: 3.3628  max mem: 39406
Epoch: [40]  [10/11]  eta: 0:00:01  lr: 0.000062  min_lr: 0.000000  loss: 1.1865 (1.0605)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6567 (1.7247)  time: 1.1169  data: 0.3058  max mem: 39406
Epoch: [40] Total time: 0:00:12 (1.1371 s / it)
2025-04-28 18:01:34 Averaged stats: lr: 0.000062  min_lr: 0.000000  loss: 1.1865 (1.0605)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6567 (1.7247)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3747  data: 2.9845  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8414  data: 1.4923  max mem: 39406
Test: Total time: 0:00:03 (1.9353 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6728 Acc: 0.7994 Recall_macro: 0.6728 Recall_weighted: 0.7994 AUC-ROC: nan Weighted F1-score: 0.7881
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 40, 'Val Loss': 0.6675599813461304, 'Val BAcc': np.float64(0.672844801231898), 'Val Acc': 0.7994186046511628, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7881036220202483, 'Val Recall_macro': 0.672844801231898, 'Val Recall_weighted': 0.7994186046511628}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [41]  [ 0/11]  eta: 0:00:46  lr: 0.000061  min_lr: 0.000000  loss: 0.6319 (0.6319)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5951 (1.5951)  time: 4.2100  data: 3.4111  max mem: 39406
Epoch: [41]  [10/11]  eta: 0:00:01  lr: 0.000050  min_lr: 0.000000  loss: 1.1554 (1.0891)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8527 (1.8838)  time: 1.1210  data: 0.3102  max mem: 39406
Epoch: [41] Total time: 0:00:12 (1.1397 s / it)
2025-04-28 18:01:50 Averaged stats: lr: 0.000050  min_lr: 0.000000  loss: 1.1554 (1.0891)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8527 (1.8838)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4146  data: 3.0251  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8624  data: 1.5126  max mem: 39406
Test: Total time: 0:00:03 (1.9571 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6976 Acc: 0.7936 Recall_macro: 0.6976 Recall_weighted: 0.7936 AUC-ROC: nan Weighted F1-score: 0.7908
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 41, 'Val Loss': 0.6671182513237, 'Val BAcc': np.float64(0.6976488662940276), 'Val Acc': 0.7936046511627907, 'Val ROC': np.float64(nan), 'Val W_F1': 0.790770610054528, 'Val Recall_macro': 0.6976488662940276, 'Val Recall_weighted': 0.7936046511627907}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [42]  [ 0/11]  eta: 0:00:43  lr: 0.000049  min_lr: 0.000000  loss: 0.9525 (0.9525)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.3863 (1.3863)  time: 3.9466  data: 3.1465  max mem: 39406
Epoch: [42]  [10/11]  eta: 0:00:01  lr: 0.000039  min_lr: 0.000000  loss: 1.0048 (1.0790)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9474 (1.9074)  time: 1.0980  data: 0.2861  max mem: 39406
Epoch: [42] Total time: 0:00:12 (1.1216 s / it)
2025-04-28 18:02:06 Averaged stats: lr: 0.000039  min_lr: 0.000000  loss: 1.0048 (1.0790)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9474 (1.9074)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4388  data: 3.0490  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8752  data: 1.5245  max mem: 39406
Test: Total time: 0:00:03 (1.9623 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6801 Acc: 0.7907 Recall_macro: 0.6801 Recall_weighted: 0.7907 AUC-ROC: nan Weighted F1-score: 0.7840
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 42, 'Val Loss': 0.6630682945251465, 'Val BAcc': np.float64(0.6801434899499416), 'Val Acc': 0.7906976744186046, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7840461549079082, 'Val Recall_macro': 0.6801434899499416, 'Val Recall_weighted': 0.7906976744186046}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [43]  [ 0/11]  eta: 0:00:45  lr: 0.000038  min_lr: 0.000000  loss: 1.2551 (1.2551)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5526 (1.5526)  time: 4.1070  data: 3.3022  max mem: 39406
Epoch: [43]  [10/11]  eta: 0:00:01  lr: 0.000029  min_lr: 0.000000  loss: 1.1404 (1.0890)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6538 (1.7613)  time: 1.1117  data: 0.3003  max mem: 39406
Epoch: [43] Total time: 0:00:12 (1.1336 s / it)
2025-04-28 18:02:23 Averaged stats: lr: 0.000029  min_lr: 0.000000  loss: 1.1404 (1.0890)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.6538 (1.7613)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4165  data: 3.0264  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8633  data: 1.5133  max mem: 39406
Test: Total time: 0:00:03 (1.9467 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6582 Acc: 0.7965 Recall_macro: 0.6582 Recall_weighted: 0.7965 AUC-ROC: nan Weighted F1-score: 0.7846
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 43, 'Val Loss': 0.6622459292411804, 'Val BAcc': np.float64(0.6582011252978995), 'Val Acc': 0.7965116279069767, 'Val ROC': np.float64(nan), 'Val W_F1': 0.784596271664053, 'Val Recall_macro': 0.6582011252978995, 'Val Recall_weighted': 0.7965116279069767}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [44]  [ 0/11]  eta: 0:00:43  lr: 0.000028  min_lr: 0.000000  loss: 1.3637 (1.3637)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7947 (1.7947)  time: 3.9471  data: 3.1423  max mem: 39406
Epoch: [44]  [10/11]  eta: 0:00:01  lr: 0.000021  min_lr: 0.000000  loss: 1.2223 (1.1386)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7947 (1.8860)  time: 1.0976  data: 0.2857  max mem: 39406
Epoch: [44] Total time: 0:00:12 (1.1224 s / it)
2025-04-28 18:02:39 Averaged stats: lr: 0.000021  min_lr: 0.000000  loss: 1.2223 (1.1386)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.7947 (1.8860)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4575  data: 3.0650  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8837  data: 1.5326  max mem: 39406
Test: Total time: 0:00:03 (1.9919 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6972 Acc: 0.7994 Recall_macro: 0.6972 Recall_weighted: 0.7994 AUC-ROC: nan Weighted F1-score: 0.7965
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 44, 'Val Loss': 0.6616138815879822, 'Val BAcc': np.float64(0.6972232978684593), 'Val Acc': 0.7994186046511628, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7965372847250958, 'Val Recall_macro': 0.6972232978684593, 'Val Recall_weighted': 0.7994186046511628}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [45]  [ 0/11]  eta: 0:00:45  lr: 0.000020  min_lr: 0.000000  loss: 1.0709 (1.0709)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.4256 (1.4256)  time: 4.1413  data: 3.3396  max mem: 39406
Epoch: [45]  [10/11]  eta: 0:00:01  lr: 0.000014  min_lr: 0.000000  loss: 1.1597 (1.1167)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8501 (1.8895)  time: 1.1149  data: 0.3037  max mem: 39406
Epoch: [45] Total time: 0:00:12 (1.1366 s / it)
2025-04-28 18:02:56 Averaged stats: lr: 0.000014  min_lr: 0.000000  loss: 1.1597 (1.1167)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8501 (1.8895)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3746  data: 2.9863  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8418  data: 1.4932  max mem: 39406
Test: Total time: 0:00:03 (1.9342 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6918 Acc: 0.7965 Recall_macro: 0.6918 Recall_weighted: 0.7965 AUC-ROC: nan Weighted F1-score: 0.7931
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 45, 'Val Loss': 0.6623463034629822, 'Val BAcc': np.float64(0.6918469537824378), 'Val Acc': 0.7965116279069767, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7931373247781138, 'Val Recall_macro': 0.6918469537824378, 'Val Recall_weighted': 0.7965116279069767}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [46]  [ 0/11]  eta: 0:00:44  lr: 0.000013  min_lr: 0.000000  loss: 1.1481 (1.1481)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.2430 (2.2430)  time: 4.0748  data: 3.2733  max mem: 39406
Epoch: [46]  [10/11]  eta: 0:00:01  lr: 0.000008  min_lr: 0.000000  loss: 1.0100 (1.1025)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8698 (1.8167)  time: 1.1088  data: 0.2977  max mem: 39406
Epoch: [46] Total time: 0:00:12 (1.1307 s / it)
2025-04-28 18:03:12 Averaged stats: lr: 0.000008  min_lr: 0.000000  loss: 1.0100 (1.1025)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8698 (1.8167)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3598  data: 2.9718  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8343  data: 1.4860  max mem: 39406
Test: Total time: 0:00:03 (1.9313 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6866 Acc: 0.8023 Recall_macro: 0.6866 Recall_weighted: 0.8023 AUC-ROC: nan Weighted F1-score: 0.7952
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 46, 'Val Loss': 0.6643323302268982, 'Val BAcc': np.float64(0.6865957671118962), 'Val Acc': 0.8023255813953488, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7952002864499804, 'Val Recall_macro': 0.6865957671118962, 'Val Recall_weighted': 0.8023255813953488}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [47]  [ 0/11]  eta: 0:00:46  lr: 0.000008  min_lr: 0.000000  loss: 0.8022 (0.8022)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.1785 (1.1785)  time: 4.1925  data: 3.3889  max mem: 39406
Epoch: [47]  [10/11]  eta: 0:00:01  lr: 0.000004  min_lr: 0.000000  loss: 0.9287 (0.9518)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5582 (1.5973)  time: 1.1196  data: 0.3081  max mem: 39406
Epoch: [47] Total time: 0:00:12 (1.1432 s / it)
2025-04-28 18:03:28 Averaged stats: lr: 0.000004  min_lr: 0.000000  loss: 0.9287 (0.9518)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.5582 (1.5973)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4008  data: 3.0111  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8557  data: 1.5056  max mem: 39406
Test: Total time: 0:00:03 (1.9560 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6866 Acc: 0.8023 Recall_macro: 0.6866 Recall_weighted: 0.8023 AUC-ROC: nan Weighted F1-score: 0.7952
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 47, 'Val Loss': 0.6649165749549866, 'Val BAcc': np.float64(0.6865957671118962), 'Val Acc': 0.8023255813953488, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7952002864499804, 'Val Recall_macro': 0.6865957671118962, 'Val Recall_weighted': 0.8023255813953488}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [48]  [ 0/11]  eta: 0:00:43  lr: 0.000004  min_lr: 0.000000  loss: 1.0785 (1.0785)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8894 (1.8894)  time: 3.9780  data: 3.1760  max mem: 39406
Epoch: [48]  [10/11]  eta: 0:00:01  lr: 0.000002  min_lr: 0.000000  loss: 1.1062 (1.0974)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8894 (1.7920)  time: 1.0997  data: 0.2888  max mem: 39406
Epoch: [48] Total time: 0:00:12 (1.1235 s / it)
2025-04-28 18:03:45 Averaged stats: lr: 0.000002  min_lr: 0.000000  loss: 1.1062 (1.0974)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.8894 (1.7920)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.4210  data: 3.0318  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8669  data: 1.5160  max mem: 39406
Test: Total time: 0:00:03 (1.9594 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6806 Acc: 0.7994 Recall_macro: 0.6806 Recall_weighted: 0.7994 AUC-ROC: nan Weighted F1-score: 0.7905
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 48, 'Val Loss': 0.664882481098175, 'Val BAcc': np.float64(0.6806049837017579), 'Val Acc': 0.7994186046511628, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7905089888744999, 'Val Recall_macro': 0.6806049837017579, 'Val Recall_weighted': 0.7994186046511628}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:118: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Epoch: [49]  [ 0/11]  eta: 0:00:45  lr: 0.000002  min_lr: 0.000000  loss: 1.2542 (1.2542)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 2.0346 (2.0346)  time: 4.1182  data: 3.3138  max mem: 39406
Epoch: [49]  [10/11]  eta: 0:00:01  lr: 0.000001  min_lr: 0.000000  loss: 1.3200 (1.2402)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9677 (1.9755)  time: 1.1141  data: 0.3013  max mem: 39406
Epoch: [49] Total time: 0:00:12 (1.1387 s / it)
2025-04-28 18:04:01 Averaged stats: lr: 0.000001  min_lr: 0.000000  loss: 1.3200 (1.2402)  loss_scale: 65536.0000 (65536.0000)  weight_decay: 0.0500 (0.0500)  grad_norm: 1.9677 (1.9755)
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/2]  eta: 0:00:06    time: 3.3741  data: 2.9826  max mem: 39406
Test:  [1/2]  eta: 0:00:01    time: 1.8433  data: 1.4914  max mem: 39406
Test: Total time: 0:00:03 (1.9449 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- val -------------
Sklearn Metrics - BAcc: 0.6806 Acc: 0.7994 Recall_macro: 0.6806 Recall_weighted: 0.7994 AUC-ROC: nan Weighted F1-score: 0.7905
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
Predictions for val saved to /home/share/FM_Code/PanDerm/Output_dir/val.csv
-------------------------- {'Epoch': 49, 'Val Loss': 0.6649270057678223, 'Val BAcc': np.float64(0.6806049837017579), 'Val Acc': 0.7994186046511628, 'Val ROC': np.float64(nan), 'Val W_F1': 0.7905089888744999, 'Val Recall_macro': 0.6806049837017579, 'Val Recall_weighted': 0.7994186046511628}
Max val mean accuracy: 0.80%
/home/share/FM_Code/PanDerm/classification/run_class_finetuning.py:724: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.
  model_dict = torch.load(model_weight)
Starting test without tta
/home/share/FM_Code/PanDerm/classification/furnace/engine_for_finetuning.py:280: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast():
Test:  [0/4]  eta: 0:00:11    time: 2.8730  data: 2.6232  max mem: 39406
Test:  [3/4]  eta: 0:00:00    time: 0.9519  data: 0.6559  max mem: 39406
Test: Total time: 0:00:04 (1.0196 s / it)
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
------------- test -------------
Sklearn Metrics - BAcc: 0.7608 Acc: 0.7874 Recall_macro: 0.7608 Recall_weighted: 0.7874 AUC-ROC: nan Weighted F1-score: 0.7925
/home/syyan/anaconda3/envs/PanDerm/lib/python3.10/site-packages/sklearn/metrics/_ranking.py:379: UndefinedMetricWarning: Only one class is present in y_true. ROC AUC score is not defined in that case.
  warnings.warn(
{'balanced_accuracy': np.float64(0.7607580040952305), 'accuracy': 0.7874186550976139, 'top3 accuracy': np.float64(0.9869848156182213), 'top5 accuracy': np.float64(0.9978308026030369), 'sensitivity': np.float64(0.7607580040952305), 'specificity': np.float64(0.9517027877483976), 'auc_roc': np.float64(nan), 'weighted_f1': 0.7925088917793152, 'recall_macro': 0.7607580040952305, 'recall_weighted': 0.7874186550976139}
Predictions for test saved to /home/share/FM_Code/PanDerm/Output_dir/test.csv
Training time 0:14:39
